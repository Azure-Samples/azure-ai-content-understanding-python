{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Custom Fields from Your Pre-transcribed File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use analyzers to extract custom fields from your pre-transcribed input files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "1. Ensure your Azure AI service is configured by following the [configuration steps](../README.md#configure-azure-ai-service-resource).\n",
    "2. Install the required packages to run the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a collection of analyzer templates designed to extract fields from various input file types.\n",
    "\n",
    "These templates are highly customizable, allowing you to adapt them to your specific requirements. For additional verified templates provided by Microsoft, please visit [here](../analyzer_templates/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_templates = {\n",
    "    \"call_recording_pretranscribe_batch\": ('../analyzer_templates/call_recording_analytics_text.json', '../data/batch_pretranscribed.json'),\n",
    "    \"call_recording_pretranscribe_fast\": ('../analyzer_templates/call_recording_analytics_text.json', '../data/fast_pretranscribed.json'),\n",
    "    \"call_recording_pretranscribe_cu\": ('../analyzer_templates/call_recording_analytics_text.json', '../data/cu_pretranscribed.json')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the analyzer template to use and assign a unique name for the analyzer that will be created from the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template = \"call_recording_pretranscribe_batch\"\n",
    "(analyzer_template_path, analyzer_sample_file_path) = extraction_templates[analyzer_template]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure AI Content Understanding Client\n",
    "\n",
    "> The [AzureContentUnderstandingClient](../python/content_understanding_client.py) is a utility class providing functions to interact with the Content Understanding API. Before the official release of the Content Understanding SDK, this class can be considered a lightweight SDK.\n",
    "\n",
    "> Fill in the constants **AZURE_AI_ENDPOINT**, **AZURE_AI_API_VERSION**, and **AZURE_AI_API_KEY** with your Azure AI Service credentials.\n",
    "\n",
    "> ‚ö†Ô∏è Important:\n",
    "Make sure to update the code below to match your chosen Azure authentication method.\n",
    "Look for the `# IMPORTANT` comments and modify those sections accordingly.\n",
    "Skipping this step may prevent the sample from running correctly.\n",
    "\n",
    "> ‚ö†Ô∏è Note: While subscription key authentication works, it is strongly recommended to use a token provider with Azure Active Directory (AAD) for improved security in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.blob import ContainerSasPermissions\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.contentunderstanding.aio import ContentUnderstandingClient\n",
    "from azure.ai.contentunderstanding.models import (\n",
    "    ContentAnalyzer,\n",
    "    ContentAnalyzerConfig,\n",
    "    FieldSchema,\n",
    "    FieldDefinition,\n",
    "    FieldType,\n",
    "    GenerationMethod,\n",
    "    AnalysisMode,\n",
    "    ProcessingLocation,\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the parent directory to the Python path to import the sample_helper module\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'python'))\n",
    "from extension.document_processor import DocumentProcessor\n",
    "from extension.sample_helper import extract_operation_id_from_poller, PollerType, save_json_to_file\n",
    "\n",
    "load_dotenv()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "endpoint = os.environ.get(\"AZURE_CONTENT_UNDERSTANDING_ENDPOINT\")\n",
    "# Return AzureKeyCredential if AZURE_CONTENT_UNDERSTANDING_KEY is set, otherwise DefaultAzureCredential\n",
    "key = os.getenv(\"AZURE_CONTENT_UNDERSTANDING_KEY\")\n",
    "credential = AzureKeyCredential(key) if key else DefaultAzureCredential()\n",
    "# Create the ContentUnderstandingClient\n",
    "client = ContentUnderstandingClient(endpoint=endpoint, credential=credential)\n",
    "print(\"‚úÖ ContentUnderstandingClient created successfully\")\n",
    "\n",
    "try:\n",
    "    processor = DocumentProcessor(client)\n",
    "    print(\"‚úÖ DocumentProcessor created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create DocumentProcessor: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Analyzer from the Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_id = f\"conversational_field_extraction-sample-{datetime.now().strftime('%Y%m%d')}-{datetime.now().strftime('%H%M%S')}-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Create a custom analyzer using object model\n",
    "print(f\"üîß Creating custom analyzer '{analyzer_id}'...\")\n",
    "\n",
    "content_analyzer = ContentAnalyzer(\n",
    "    base_analyzer_id=\"prebuilt-audioAnalyzer\",\n",
    "    config=ContentAnalyzerConfig(\n",
    "        return_details=True,\n",
    "    ),\n",
    "    description=\"Sample call recording analytics\",\n",
    "    field_schema=FieldSchema(\n",
    "        fields={\n",
    "            \"Summary\": FieldDefinition(\n",
    "                description=\"A one-paragraph summary\",\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                type=FieldType.STRING,\n",
    "            ),\n",
    "            \"Topics\": FieldDefinition(\n",
    "                description=\"Top 5 topics mentioned\",\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                items_property={\n",
    "                    \"type\": \"string\",\n",
    "                }\n",
    "            ),\n",
    "            \"Companies\": FieldDefinition(\n",
    "                description=\"List of companies mentioned\",\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                items_property={\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            ),\n",
    "            \"People\": FieldDefinition(\n",
    "                description=\"List of people mentioned\",\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.OBJECT,\n",
    "                    properties={\n",
    "                        \"Name\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            description=\"Person's name\"\n",
    "                        ),\n",
    "                        \"Role\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            description=\"Person's title/role\"\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            ),\n",
    "            \"Sentiment\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=GenerationMethod.CLASSIFY,\n",
    "                description=\"Overall sentiment\",\n",
    "                enum=[\n",
    "                    \"Positive\",\n",
    "                    \"Neutral\",\n",
    "                    \"Negative\"\n",
    "                ]\n",
    "            ),\n",
    "            \"Categories\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.CLASSIFY,\n",
    "                description=\"List of relevant categories\",\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.STRING,\n",
    "                    enum=[\n",
    "                        \"Agriculture\",\n",
    "                        \"Business\",\n",
    "                        \"Finance\",\n",
    "                        \"Health\",\n",
    "                        \"Insurance\",\n",
    "                        \"Mining\",\n",
    "                        \"Pharmaceutical\",\n",
    "                        \"Retail\",\n",
    "                        \"Technology\",\n",
    "                        \"Transportation\"\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Start the analyzer creation operation\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=analyzer_id,\n",
    "    resource=content_analyzer,\n",
    "    content_type=\"application/json\"\n",
    ")\n",
    "\n",
    "# Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"üìã Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"‚è≥ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"‚úÖ Analyzer '{analyzer_id}' created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Fields Using the Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the analyzer is successfully created, you can use it to analyze your input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extension.transcripts_processor import TranscriptsProcessor\n",
    "\n",
    "test_file_path = analyzer_sample_file_path\n",
    "\n",
    "transcripts_processor = TranscriptsProcessor()\n",
    "webvtt_output, webvtt_output_file_path = transcripts_processor.convert_file(test_file_path)\n",
    "\n",
    "if \"WEBVTT\" not in webvtt_output:\n",
    "    print(\"Error: The output is not in WebVTT format.\")\n",
    "else:\n",
    "    # Read the sample invoice PDF file\n",
    "    with open(webvtt_output_file_path, 'r', encoding='utf-8') as f:\n",
    "        webvtt_content = f.read()\n",
    "\n",
    "    print(f\"‚úÖ Sample WebVTT file read successfully from {webvtt_output_file_path}\")\n",
    "    # Begin document analysis operation\n",
    "    print(f\"üîç Starting document analysis with analyzer '{analyzer_id}'...\")\n",
    "    analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "        analyzer_id=analyzer_id,\n",
    "        input=webvtt_content,\n",
    "        content_type=\"application/octet-stream\",\n",
    "    )\n",
    "\n",
    "    # Wait for analysis completion\n",
    "    print(f\"‚è≥ Waiting for document analysis to complete...\")\n",
    "    analysis_result = await analysis_poller.result()\n",
    "    print(f\"‚úÖ Document analysis completed successfully!\")\n",
    "\n",
    "    # Extract operation ID for get_result\n",
    "    analysis_operation_id = extract_operation_id_from_poller(\n",
    "        analysis_poller, PollerType.ANALYZE_CALL\n",
    "    )\n",
    "    print(f\"üìã Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "    # Get the analysis result using the operation ID\n",
    "    print(\n",
    "        f\"üîç Getting analysis result using operation ID '{analysis_operation_id}'...\"\n",
    "    )\n",
    "    operation_status = await client.content_analyzers.get_result(\n",
    "        operation_id=analysis_operation_id,\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Analysis result retrieved successfully!\")\n",
    "    print(f\"   Operation ID: {operation_status.id}\")\n",
    "    print(f\"   Status: {operation_status.status}\")\n",
    "\n",
    "    # The actual analysis result is in operation_status.result\n",
    "    operation_result = operation_status.result\n",
    "    if operation_result is None:\n",
    "        print(\"‚ö†Ô∏è  No analysis result available\")\n",
    "        \n",
    "    print(f\"   Result contains {len(operation_result.contents)} contents\")\n",
    "\n",
    "    # Save the analysis result to a file\n",
    "    saved_file_path = save_json_to_file(\n",
    "        result=operation_result.as_dict(),\n",
    "        filename_prefix=\"conversational_field_extraction_get_result\",\n",
    "    )\n",
    "    print(f\"üíæ Analysis result saved to: {saved_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "Optionally, delete the sample analyzer from your Azure resource. In typical usage scenarios, you would analyze multiple files using the same analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the created analyzer (demo cleanup)\n",
    "print(f\"üóëÔ∏è  Deleting analyzer '{analyzer_id}' (demo cleanup)...\")\n",
    "await client.content_analyzers.delete(analyzer_id=analyzer_id)\n",
    "print(f\"‚úÖ Analyzer '{analyzer_id}' deleted successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
