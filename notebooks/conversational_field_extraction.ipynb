{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Custom Fields from Your Pretranscribed File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use analyzers to extract custom fields from your transcription input files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "1. Ensure Azure AI service is configured following [steps](../README.md#configure-azure-ai-service-resource)\n",
    "2. Install the required packages to run the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: azure-identity in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 1)) (1.23.0)\n",
      "Requirement already satisfied: python-dotenv in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: requests in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: Pillow in /home/vscode/.local/lib/python3.11/site-packages (from -r ../requirements.txt (line 4)) (11.2.1)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 1)) (1.34.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 1)) (45.0.3)\n",
      "Requirement already satisfied: msal>=1.30.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 1)) (1.32.3)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-identity->-r ../requirements.txt (line 1)) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.11/site-packages (from requests->-r ../requirements.txt (line 3)) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-core>=1.31.0->azure-identity->-r ../requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.14 in /home/vscode/.local/lib/python3.11/site-packages (from cryptography>=2.5->azure-identity->-r ../requirements.txt (line 1)) (1.17.1)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->-r ../requirements.txt (line 1)) (2.10.1)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.11/site-packages (from cffi>=1.14->cryptography>=2.5->azure-identity->-r ../requirements.txt (line 1)) (2.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a collection of analyzer templates designed to extract fields from various input file types.\n",
    "\n",
    "These templates are highly customizable, allowing you to modify them to suit your specific needs. For additional verified templates from Microsoft, please visit [here](../analyzer_templates/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_templates = {\n",
    "    \"call_recording_pretranscribe_batch\": ('../analyzer_templates/call_recording_analytics_text.json', '../data/batch_pretranscribed.json'),\n",
    "    \"call_recording_pretranscribe_fast\": ('../analyzer_templates/call_recording_analytics_text.json', '../data/fast_pretranscribed.json'),\n",
    "    \"call_recording_pretranscribe_cu\": ('../analyzer_templates/call_recording_analytics_text.json', '../data/cu_pretranscribed.json')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the analyzer template you want to use and provide a name for the analyzer to be created based on the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "ANALYZER_TEMPLATE = \"call_recording_pretranscribe_batch\"\n",
    "ANALYZER_ID = \"prebuilt-callCenter\"\n",
    "\n",
    "(analyzer_template_path, analyzer_sample_file_path) = extraction_templates[ANALYZER_TEMPLATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure AI Content Understanding Client\n",
    "\n",
    "> The [AzureContentUnderstandingClient](../python/content_understanding_client.py) is a utility class containing functions to interact with the Content Understanding API. Before the official release of the Content Understanding SDK, it can be regarded as a lightweight SDK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:azure.identity._credentials.environment:No environment configuration found.\n",
      "INFO:azure.identity._credentials.managed_identity:ManagedIdentityCredential will use IMDS\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'http://169.254.169.254/metadata/identity/oauth2/token?api-version=REDACTED&resource=REDACTED'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'User-Agent': 'azsdk-python-identity/1.23.0 Python/3.11.12 (Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.36)'\n",
      "No body was attached to the request\n",
      "INFO:azure.identity._credentials.chained:DefaultAzureCredential acquired a token from AzureDeveloperCliCredential\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "AZURE_AI_ENDPOINT = os.getenv(\"AZURE_AI_ENDPOINT\")\n",
    "AZURE_AI_API_VERSION = os.getenv(\"AZURE_AI_API_VERSION\", \"2025-05-01-preview\")\n",
    "\n",
    "# Add the parent directory to the path to use shared modules\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "from python.content_understanding_client import AzureContentUnderstandingClient\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = AzureContentUnderstandingClient(\n",
    "    endpoint=AZURE_AI_ENDPOINT,\n",
    "    api_version=AZURE_AI_API_VERSION,\n",
    "    token_provider=token_provider,\n",
    "    # x_ms_useragent=\"azure-ai-content-understanding-python/field_extraction\", # This header is used for sample usage telemetry, please comment out this line if you want to opt out.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Fields Using the Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the analyzer is successfully created, we can use it to analyze our input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load transcription completed.\n",
      "processing a fast transcription file.\n",
      "Fast to WebVTT Conversion completed.\n",
      "Conversion completed. The result has been saved to '../data/transcripts_processor_output/batch_pretranscribed.json.convertedTowebVTT.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:python.content_understanding_client:Analyzing file ../data/transcripts_processor_output/batch_pretranscribed.json.convertedTowebVTT.txt with analyzer: prebuilt-callCenter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: <Response [202]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:python.content_understanding_client:Request 4c2c7f32-0b29-4be4-b4a5-240feeb85109 in progress ...\n",
      "INFO:python.content_understanding_client:Request 4c2c7f32-0b29-4be4-b4a5-240feeb85109 in progress ...\n",
      "INFO:python.content_understanding_client:Request 4c2c7f32-0b29-4be4-b4a5-240feeb85109 in progress ...\n",
      "INFO:python.content_understanding_client:Request 4c2c7f32-0b29-4be4-b4a5-240feeb85109 in progress ...\n",
      "INFO:python.content_understanding_client:Request 4c2c7f32-0b29-4be4-b4a5-240feeb85109 in progress ...\n",
      "INFO:python.content_understanding_client:Request 4c2c7f32-0b29-4be4-b4a5-240feeb85109 in progress ...\n",
      "INFO:python.content_understanding_client:Request result is ready after 17.41 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"4c2c7f32-0b29-4be4-b4a5-240feeb85109\",\n",
      "  \"status\": \"Succeeded\",\n",
      "  \"result\": {\n",
      "    \"analyzerId\": \"prebuilt-callCenter\",\n",
      "    \"apiVersion\": \"2025-05-01-preview\",\n",
      "    \"createdAt\": \"2025-06-06T05:39:22Z\",\n",
      "    \"stringEncoding\": \"utf8\",\n",
      "    \"warnings\": [],\n",
      "    \"contents\": [\n",
      "      {\n",
      "        \"markdown\": \"# Audio: 00:00.000 => 00:00.000\\n\\nTranscript\\n```\\nWEBVTT\\n\\n\\n```\",\n",
      "        \"fields\": {\n",
      "          \"Summary\": {\n",
      "            \"type\": \"string\",\n",
      "            \"valueString\": \"The transcript does not contain any meaningful content or conversation.\"\n",
      "          },\n",
      "          \"Sentiment\": {\n",
      "            \"type\": \"string\",\n",
      "            \"valueString\": \"Neutral\"\n",
      "          }\n",
      "        },\n",
      "        \"kind\": \"audioVisual\",\n",
      "        \"startTimeMs\": 0,\n",
      "        \"endTimeMs\": 0,\n",
      "        \"transcriptPhrases\": []\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from python.extension.transcripts_processor import TranscriptsProcessor\n",
    "\n",
    "test_file_path=analyzer_sample_file_path\n",
    "\n",
    "transcripts_processor = TranscriptsProcessor()\n",
    "webvtt_output, webvtt_output_file_path = transcripts_processor.convert_file(test_file_path)\n",
    "\n",
    "if \"WEBVTT\" not in webvtt_output:\n",
    "    print(\"Error: The output is not in WebVTT format.\")\n",
    "else:    \n",
    "    response = client.begin_analyze(ANALYZER_ID, file_location=webvtt_output_file_path)\n",
    "    print(\"Response:\", response)\n",
    "    result_json = client.poll_result(response)\n",
    "\n",
    "print(json.dumps(result_json, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The markdown output contains layout information, which is very useful for Retrieval-Augmented Generation (RAG) scenarios. You can paste the markdown into a viewer such as Visual Studio Code and preview the layout structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Audio: 00:00.000 => 00:00.000\n",
      "\n",
      "Transcript\n",
      "```\n",
      "WEBVTT\n",
      "\n",
      "\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "  print(result_json[\"result\"][\"contents\"][0][\"markdown\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can get the layout information, including ```words/lines``` in the pagesnode and paragraphs info in ```paragraphs```, and ```tables``` in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"markdown\": \"# Audio: 00:00.000 => 00:00.000\\n\\nTranscript\\n```\\nWEBVTT\\n\\n\\n```\",\n",
      "  \"fields\": {\n",
      "    \"Summary\": {\n",
      "      \"type\": \"string\",\n",
      "      \"valueString\": \"The transcript does not contain any meaningful content or conversation.\"\n",
      "    },\n",
      "    \"Sentiment\": {\n",
      "      \"type\": \"string\",\n",
      "      \"valueString\": \"Neutral\"\n",
      "    }\n",
      "  },\n",
      "  \"kind\": \"audioVisual\",\n",
      "  \"startTimeMs\": 0,\n",
      "  \"endTimeMs\": 0,\n",
      "  \"transcriptPhrases\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(result_json[\"result\"][\"contents\"][0], indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
