{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Custom Fields from Your File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use analyzers to extract custom fields from your input files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "1. Ensure Azure AI service is configured following [steps](../README.md#configure-azure-ai-service-resource)\n",
    "2. Install the required packages to run the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure AI Content Understanding Client\n",
    "\n",
    "> The [AzureContentUnderstandingClient](../python/content_understanding_client.py) is a utility class containing functions to interact with the Content Understanding API. Before the official release of the Content Understanding SDK, it can be regarded as a lightweight SDK. Fill the constant **AZURE_AI_ENDPOINT**, **AZURE_AI_API_VERSION**, **AZURE_AI_API_KEY** with the information from your Azure AI Service.\n",
    "\n",
    "> ‚ö†Ô∏è Important:\n",
    "You must update the code below to match your Azure authentication method.\n",
    "Look for the `# IMPORTANT` comments and modify those sections accordingly.\n",
    "If you skip this step, the sample may not run correctly.\n",
    "\n",
    "> ‚ö†Ô∏è Note: Using a subscription key works, but using a token provider with Azure Active Directory (AAD) is much safer and is highly recommended for production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.blob import ContainerSasPermissions\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.contentunderstanding.aio import ContentUnderstandingClient\n",
    "from azure.ai.contentunderstanding.models import (\n",
    "    ContentAnalyzer,\n",
    "    ContentAnalyzerConfig,\n",
    "    FieldSchema,\n",
    "    FieldDefinition,\n",
    "    FieldType,\n",
    "    GenerationMethod,\n",
    "    AnalysisMode,\n",
    "    ProcessingLocation,\n",
    "    SegmentationMode\n",
    ")\n",
    "\n",
    "# Add the parent directory to the Python path to import the sample_helper module\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'python'))\n",
    "from extension.document_processor import DocumentProcessor\n",
    "from extension.sample_helper import extract_operation_id_from_poller, PollerType, save_json_to_file\n",
    "\n",
    "load_dotenv()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "endpoint = os.environ.get(\"AZURE_CONTENT_UNDERSTANDING_ENDPOINT\")\n",
    "# Return AzureKeyCredential if AZURE_CONTENT_UNDERSTANDING_KEY is set, otherwise DefaultAzureCredential\n",
    "key = os.getenv(\"AZURE_CONTENT_UNDERSTANDING_KEY\")\n",
    "credential = AzureKeyCredential(key) if key else DefaultAzureCredential()\n",
    "# Create the ContentUnderstandingClient\n",
    "client = ContentUnderstandingClient(endpoint=endpoint, credential=credential)\n",
    "print(\"‚úÖ ContentUnderstandingClient created successfully\")\n",
    "\n",
    "try:\n",
    "    processor = DocumentProcessor(client)\n",
    "    print(\"‚úÖ DocumentProcessor created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create DocumentProcessor: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates field extraction across multiple modalities using Azure AI Content Understanding. We'll walk through each modality step by step:\n",
    "\n",
    "1. **Document Analysis** - Extract fields from invoices and receipts\n",
    "2. **Audio Analysis** - Process call recordings and conversation audio  \n",
    "3. **Video Analysis** - Analyze marketing videos and extract insights\n",
    "4. **Image Analysis** - Extract information from charts and images\n",
    "\n",
    "Each section will create an analyzer, process sample data, display results, and clean up the analyzer before moving to the next modality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Analyzer Templates and Schemas\n",
    "\n",
    "Before we create our first analyzer, it's important to understand the structure and schema of analyzer templates. Custom analyzers in Azure AI Content Understanding are defined using JSON templates that specify what fields to extract and how to process the content.\n",
    "\n",
    "**Key Schema Components:**\n",
    "\n",
    "- **`baseAnalyzerId`**: This is crucial as it specifies which prebuilt analyzer to derive from (e.g., `prebuilt-documentAnalyzer`, `prebuilt-audioAnalyzer`, `prebuilt-videoAnalyzer`, `prebuilt-imageAnalyzer`, `prebuilt-callCenter`). This provides the foundation capabilities for your custom analyzer.\n",
    "\n",
    "- **`fields`**: Define the specific data points you want to extract. Each field has:\n",
    "  - **Field name**: The identifier for the extracted data (required and important for referencing results)\n",
    "  - **Description**: Optional but helpful for documentation and understanding the field's purpose\n",
    "  - **Method**: Can be `\"extract\"` (for extracting existing information from documents - currently only available for document analysis) or `\"generate\"` (for generating new insights using AI)\n",
    "\n",
    "- **`method`**: The overall extraction approach - use `\"extract\"` for standard field extraction from documents or `\"generate\"` when you need AI to generate insights or summaries.\n",
    "\n",
    "**Important Note**: The `\"extract\"` method is currently only available for document analysis (using `prebuilt-documentAnalyzer`). For other modalities like audio, video, and images, use the `\"generate\"` method.\n",
    "\n",
    "Let's examine the invoice template to see these concepts in action:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the schema for document modality used to extract fields from an invoice PDF. This analyzer identifies key invoice elements such as vendor information, amounts, dates, and line items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/invoice.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example schema for the video modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/marketing_video.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Analysis\n",
    "\n",
    "Let's start with document analysis by extracting fields from invoices and receipts. This modality is excellent for processing structured documents and extracting key information like amounts, dates, vendor details, and line items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Invoice Field Extraction\n",
    "\n",
    "Let's extract fields from an invoice PDF. This analyzer identifies essential invoice elements such as vendor information, amounts, dates, and line items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/invoice.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Invoice Analyzer**\n",
    "\n",
    "Now let's create the invoice analyzer and process our sample invoice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_analyzer_id = \"invoice-extraction-sample-\" + str(uuid.uuid4())\n",
    "\n",
    "invoice_analyzer = ContentAnalyzer(\n",
    "    base_analyzer_id=\"prebuilt-documentAnalyzer\",\n",
    "    description=\"Sample invoice analyzer\",\n",
    "    field_schema=FieldSchema(\n",
    "        fields={\n",
    "            \"VendorName\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=GenerationMethod.EXTRACT,\n",
    "                description=\"Vendor issuing the invoice\"\n",
    "            ),\n",
    "            \"Items\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.EXTRACT,\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.OBJECT,\n",
    "                    properties={\n",
    "                        \"Description\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.EXTRACT,\n",
    "                            description=\"Description of the item\"\n",
    "                        ),\n",
    "                        \"Amount\": FieldDefinition(\n",
    "                            type=FieldType.NUMBER,\n",
    "                            method=GenerationMethod.EXTRACT,\n",
    "                            description=\"Amount of the item\"\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "print(f\"{json.dumps(invoice_analyzer.as_dict(), indent=2)}\")\n",
    "# Start the analyzer creation operation\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=invoice_analyzer_id,\n",
    "    resource=invoice_analyzer,\n",
    ")\n",
    "\n",
    "# Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"üìã Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"‚è≥ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"‚úÖ Analyzer '{invoice_analyzer_id}' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/invoice.pdf'\n",
    "\n",
    "with open(sample_file_path, 'rb') as f:\n",
    "    invoice_content = f.read()\n",
    "\n",
    "# Begin document analysis operation\n",
    "print(f\"üîç Starting document analysis with analyzer '{invoice_analyzer_id}'...\")\n",
    "analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=invoice_analyzer_id,\n",
    "    input=invoice_content,\n",
    "    content_type=\"application/pdf\",\n",
    ")\n",
    "\n",
    "# Wait for analysis completion\n",
    "print(f\"‚è≥ Waiting for document analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(f\"‚úÖ Document analysis completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result\n",
    "analysis_operation_id = extract_operation_id_from_poller(\n",
    "    analysis_poller, PollerType.ANALYZE_CALL\n",
    ")\n",
    "print(f\"üìã Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "# Get the analysis result using the operation ID\n",
    "print(\n",
    "    f\"üîç Getting analysis result using operation ID '{analysis_operation_id}'...\"\n",
    ")\n",
    "operation_status = await client.content_analyzers.get_result(\n",
    "    operation_id=analysis_operation_id,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Analysis result retrieved successfully!\")\n",
    "print(f\"   Operation ID: {operation_status.id}\")\n",
    "print(f\"   Status: {operation_status.status}\")\n",
    "\n",
    "# The actual analysis result is in operation_status.result\n",
    "operation_result = operation_status.result\n",
    "if operation_result is None:\n",
    "    print(\"‚ö†Ô∏è  No analysis result available\")\n",
    "\n",
    "print(f\"   Result contains {len(operation_result.contents)} contents\")\n",
    "\n",
    "# Save the analysis result to a file\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=operation_result.as_dict(),\n",
    "    filename_prefix=\"invoice_analyzers_get_result\",\n",
    ")\n",
    "print(f\"üíæ Analysis result saved to: {saved_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invoice Analysis Results**\n",
    "\n",
    "Let's examine the extracted fields from the invoice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(operation_result.as_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Invoice Analyzer**\n",
    "\n",
    "Clean up the analyzer to manage resources (in production, you would typically keep analyzers for reuse):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await client.content_analyzers.delete(invoice_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Invoice Field Extraction with Source Grounding\n",
    "\n",
    "Now let's analyze the same invoice but with enhanced field source information and confidence scores. This provides additional context about where each extracted field was found in the document.\n",
    "\n",
    "**Note**: This custom analyzer is for demo purposes only. In production, users should start from `prebuilt-invoice` for invoice processing.\n",
    "\n",
    "**Key Feature**: This analyzer template uses `estimateFieldSourceAndConfidence: true` in the 'config', which enables the service to provide detailed information about:\n",
    "- **Field source locations**: Exact coordinates and bounding boxes where each field was found\n",
    "- **Confidence scores**: How confident the service is about each extracted field\n",
    "- **Enhanced metadata**: Additional context about the extraction process\n",
    "\n",
    "This is particularly useful for applications that need to verify extraction accuracy or provide visual feedback about where information was found in the source document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/invoice_field_source.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Invoice Field Source Analyzer**\n",
    "\n",
    "Now let's create the enhanced analyzer and process the invoice with source grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_source_analyzer_id = \"invoice-source-extraction-sample-\" + str(uuid.uuid4())\n",
    "\n",
    "invoice_source_analyzer = ContentAnalyzer(\n",
    "    base_analyzer_id=\"prebuilt-documentAnalyzer\",\n",
    "    description=\"Sample invoice analyzer\",\n",
    "    field_schema=FieldSchema(\n",
    "        fields={\n",
    "            \"VendorName\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=GenerationMethod.EXTRACT,\n",
    "                description=\"Vendor issuing the invoice\"\n",
    "            ),\n",
    "            \"Items\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.EXTRACT,\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.OBJECT,\n",
    "                    properties={\n",
    "                        \"Description\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.EXTRACT,\n",
    "                            description=\"Description of the item\"\n",
    "                        ),\n",
    "                        \"Amount\": FieldDefinition(\n",
    "                            type=FieldType.NUMBER,\n",
    "                            method=GenerationMethod.EXTRACT,\n",
    "                            description=\"Amount of the item\"\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "print(f\"{json.dumps(invoice_source_analyzer.as_dict(), indent=2)}\")\n",
    "# Start the analyzer creation operation\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=invoice_source_analyzer_id,\n",
    "    resource=invoice_source_analyzer,\n",
    ")\n",
    "\n",
    "# Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"üìã Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"‚è≥ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"‚úÖ Analyzer '{invoice_source_analyzer_id}' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/invoice.pdf'\n",
    "\n",
    "with open(sample_file_path, 'rb') as f:\n",
    "    invoice_source_content = f.read()\n",
    "\n",
    "# Begin document analysis operation\n",
    "print(f\"üîç Starting document analysis with analyzer '{invoice_source_analyzer_id}'...\")\n",
    "analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=invoice_source_analyzer_id,\n",
    "    input=invoice_source_content,\n",
    "    content_type=\"application/pdf\",\n",
    ")\n",
    "\n",
    "# Wait for analysis completion\n",
    "print(f\"‚è≥ Waiting for document analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(f\"‚úÖ Document analysis completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result\n",
    "analysis_operation_id = extract_operation_id_from_poller(\n",
    "    analysis_poller, PollerType.ANALYZE_CALL\n",
    ")\n",
    "print(f\"üìã Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "# Get the analysis result using the operation ID\n",
    "print(\n",
    "    f\"üîç Getting analysis result using operation ID '{analysis_operation_id}'...\"\n",
    ")\n",
    "operation_status = await client.content_analyzers.get_result(\n",
    "    operation_id=analysis_operation_id,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Analysis result retrieved successfully!\")\n",
    "print(f\"   Operation ID: {operation_status.id}\")\n",
    "print(f\"   Status: {operation_status.status}\")\n",
    "\n",
    "# The actual analysis result is in operation_status.result\n",
    "operation_result = operation_status.result\n",
    "if operation_result is None:\n",
    "    print(\"‚ö†Ô∏è  No analysis result available\")\n",
    "\n",
    "print(f\"   Result contains {len(operation_result.contents)} contents\")\n",
    "\n",
    "# Save the analysis result to a file\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=operation_result.as_dict(),\n",
    "    filename_prefix=\"invoice_source_content_analyzers_get_result\",\n",
    ")\n",
    "print(f\"üíæ Analysis result saved to: {saved_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invoice Field Source Analysis Results**\n",
    "\n",
    "Let's review the enhanced results, which include detailed field source locations and confidence scores. Pay special attention to the `confidence` and `source` attributes for each extracted field. The `source` attribute provides the page number and bounding box coordinates for the extracted data, offering precise context for verification and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(operation_result.as_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Invoice Field Source Analyzer**\n",
    "\n",
    "Clean up the field source analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üóëÔ∏è  Deleting analyzer '{invoice_source_analyzer_id}' (demo cleanup)...\")\n",
    "await client.content_analyzers.delete(analyzer_id=invoice_source_analyzer_id)\n",
    "print(f\"‚úÖ Analyzer '{invoice_source_analyzer_id}' deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Receipt Field Extraction\n",
    "\n",
    "Let's extract information from a receipt image. This demonstrates how the same Content Understanding service can handle different document types and formats.\n",
    "\n",
    "**Receipt Analyzer Template**\n",
    "\n",
    "Let's examine the receipt analyzer template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/receipt.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Receipt Analyzer**\n",
    "\n",
    "Now let's create the receipt analyzer and process our sample receipt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt_analyzer_id = \"receipt-extraction-\" + str(uuid.uuid4())\n",
    "\n",
    "image_analyzer = ContentAnalyzer(\n",
    "    base_analyzer_id=\"prebuilt-documentAnalyzer\",\n",
    "    description=\"Sample receipt analyzer\",\n",
    "    mode=AnalysisMode.STANDARD,\n",
    "    processing_location=ProcessingLocation.GLOBAL,\n",
    "    tags={\"demo_type\": \"image_analysis\"},\n",
    ")\n",
    "\n",
    "# Start the analyzer creation operation\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=receipt_analyzer_id,\n",
    "    resource=image_analyzer,\n",
    ")\n",
    "\n",
    "# Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"üìã Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"‚è≥ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"‚úÖ Analyzer '{receipt_analyzer_id}' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/receipt.png'\n",
    "\n",
    "with open(sample_file_path, 'rb') as f:\n",
    "    image_bytes: bytes = f.read()\n",
    "\n",
    "print(f\"üîç Analyzing {sample_file_path} with prebuilt-documentAnalyzer...\")\n",
    "\n",
    "analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=receipt_analyzer_id, \n",
    "    input=image_bytes,\n",
    "    content_type=\"application/octet-stream\")\n",
    "\n",
    "# Wait for analysis completion\n",
    "print(f\"‚è≥ Waiting for document analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(f\"‚úÖ Document analysis completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result\n",
    "analysis_operation_id = extract_operation_id_from_poller(\n",
    "    analysis_poller, PollerType.ANALYZE_CALL\n",
    ")\n",
    "print(f\"üìã Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "# Get the analysis result using the operation ID\n",
    "print(\n",
    "    f\"üîç Getting analysis result using operation ID '{analysis_operation_id}'...\"\n",
    ")\n",
    "operation_status = await client.content_analyzers.get_result(\n",
    "    operation_id=analysis_operation_id,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Analysis result retrieved successfully!\")\n",
    "print(f\"   Operation ID: {operation_status.id}\")\n",
    "print(f\"   Status: {operation_status.status}\")\n",
    "\n",
    "# The actual analysis result is in operation_status.result\n",
    "operation_result = operation_status.result\n",
    "if operation_result is None:\n",
    "    print(\"‚ö†Ô∏è  No analysis result available\")\n",
    "    \n",
    "print(f\"   Result contains {len(operation_result.contents)} contents\")\n",
    "\n",
    "# Save the analysis result to a file\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=operation_result.as_dict(),\n",
    "    filename_prefix=\"image_analyzer_get_result\",\n",
    ")\n",
    "print(f\"üíæ Analysis result saved to: {saved_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Receipt Analysis Results**\n",
    "\n",
    "Let's examine the extracted fields from the receipt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(operation_result.as_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Receipt Analyzer**\n",
    "\n",
    "Clean up the receipt analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üóëÔ∏è  Deleting analyzer '{receipt_analyzer_id}' (demo cleanup)...\")\n",
    "await client.content_analyzers.delete(analyzer_id=receipt_analyzer_id)\n",
    "print(f\"‚úÖ Analyzer '{receipt_analyzer_id}' deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Analysis\n",
    "\n",
    "Now let's move to audio analysis. This modality allows us to extract insights from audio files such as call recordings, including summaries, sentiment analysis, topic identification, and entity extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Call Recording Analytics\n",
    "\n",
    "Let's analyze a call center recording to extract insights such as summary, topics discussed, mentioned companies, and people involved in the conversation.\n",
    "\n",
    "**Call Recording Analytics Template**\n",
    "\n",
    "Let's examine the call recording analytics template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_analyzer_id = \"call-recording-analytics-\" + str(uuid.uuid4())\n",
    "# Create a custom analyzer using object model\n",
    "print(f\"üîß Creating custom analyzer '{call_analyzer_id}'...\")\n",
    "\n",
    "call_analyzer = ContentAnalyzer(\n",
    "    base_analyzer_id=\"prebuilt-callCenter\",\n",
    "    description=\"Sample call recording analytics\",\n",
    "    config=ContentAnalyzerConfig(\n",
    "        return_details=True,\n",
    "        locales=[\"en-US\"]\n",
    "    ),\n",
    "    field_schema=FieldSchema(\n",
    "        fields={\n",
    "            \"Summary\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"A one-paragraph summary\"\n",
    "            ),\n",
    "            \"Topics\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"Top 5 topics mentioned\",\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.STRING\n",
    "                )\n",
    "            ),\n",
    "            \"Companies\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"List of companies mentioned\",\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.STRING\n",
    "                )\n",
    "            ),\n",
    "            \"People\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"List of people mentioned\",\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.OBJECT,\n",
    "                    properties={\n",
    "                        \"Name\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            description=\"Person's name\"\n",
    "                        ),\n",
    "                        \"Role\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            description=\"Person's title/role\"\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            ),\n",
    "            \"Sentiment\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=GenerationMethod.CLASSIFY,\n",
    "                description=\"Overall sentiment\",\n",
    "                enum=[\n",
    "                  \"Positive\",\n",
    "                  \"Neutral\",\n",
    "                  \"Negative\"\n",
    "                ]\n",
    "            ),\n",
    "            \"Categories\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.CLASSIFY,\n",
    "                description=\"List of relevant categories\",\n",
    "                items_property=FieldDefinition(\n",
    "                  type=FieldType.STRING,\n",
    "                  enum=[\n",
    "                    \"Agriculture\",\n",
    "                    \"Business\",\n",
    "                    \"Finance\",\n",
    "                    \"Health\",\n",
    "                    \"Insurance\",\n",
    "                    \"Mining\",\n",
    "                    \"Pharmaceutical\",\n",
    "                    \"Retail\",\n",
    "                    \"Technology\",\n",
    "                    \"Transportation\"\n",
    "                  ]\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Start the analyzer creation operation\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=call_analyzer_id,\n",
    "    resource=call_analyzer,\n",
    ")\n",
    "\n",
    "# Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"üìã Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"‚è≥ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"‚úÖ Analyzer '{call_analyzer_id}' created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run call recording analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sample MP3 file\n",
    "sample_file_path = '../data/callCenterRecording.mp3'\n",
    "print(f\"üìÑ Reading audio file: {sample_file_path}\")\n",
    "with open(sample_file_path, 'rb') as f:\n",
    "    audio_data = f.read()\n",
    "\n",
    "# Begin document analysis operation\n",
    "print(f\"üîç Starting document analysis with analyzer '{call_analyzer_id}'...\")\n",
    "analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=call_analyzer_id,\n",
    "    input=audio_data,\n",
    "    content_type=\"application/octet-stream\",\n",
    ")\n",
    "\n",
    "# Wait for analysis completion\n",
    "print(f\"‚è≥ Waiting for audio analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(f\"‚úÖ Audio analysis completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result\n",
    "analysis_operation_id = extract_operation_id_from_poller(\n",
    "    analysis_poller, PollerType.ANALYZE_CALL\n",
    ")\n",
    "print(f\"üìã Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "# Get the analysis result using the operation ID\n",
    "print(\n",
    "    f\"üîç Getting analysis result using operation ID '{analysis_operation_id}'...\"\n",
    ")\n",
    "operation_status = await client.content_analyzers.get_result(\n",
    "    operation_id=analysis_operation_id,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Analysis result retrieved successfully!\")\n",
    "print(f\"   Operation ID: {operation_status.id}\")\n",
    "print(f\"   Status: {operation_status.status}\")\n",
    "\n",
    "# The actual analysis result is in operation_status.result\n",
    "operation_result = operation_status.result\n",
    "if operation_result is None:\n",
    "    print(\"‚ö†Ô∏è  No analysis result available\")\n",
    "\n",
    "print(f\"   Result contains {len(operation_result.contents)} contents\")\n",
    "\n",
    "# Save the analysis result to a file\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=operation_result.as_dict(),\n",
    "    filename_prefix=\"call_analyzer_get_result\",\n",
    ")\n",
    "print(f\"üíæ Analysis result saved to: {saved_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call recording analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(operation_result.as_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up call recording analyzer\n",
    "\n",
    "Note: In production environments, you would typically keep analyzers for reuse rather than deleting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üóëÔ∏è  Deleting analyzer '{call_analyzer_id}' (demo cleanup)...\")\n",
    "await client.content_analyzers.delete(analyzer_id=call_analyzer_id)\n",
    "print(f\"‚úÖ Analyzer '{call_analyzer_id}' deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conversational Audio Analytics\n",
    "\n",
    "Let's analyze the same audio file but with a focus on conversational aspects like sentiment analysis and dialogue understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run conversational audio analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_analyzer_id = \"conversational-audio-analytics-\" + str(uuid.uuid4())\n",
    "# Create a custom analyzer using object model\n",
    "print(f\"üîß Creating custom analyzer '{conversation_analyzer_id}'...\")\n",
    "\n",
    "conversation_analyzer = ContentAnalyzer(\n",
    "    description=\"Sample conversational audio analytics\",\n",
    "    base_analyzer_id=\"prebuilt-audioAnalyzer\",\n",
    "    config={\n",
    "      \"returnDetails\": True,\n",
    "      \"locales\": [\"en-US\"]\n",
    "    },\n",
    "    field_schema=FieldSchema(\n",
    "      fields={\n",
    "        \"Summary\": FieldDefinition(\n",
    "          type=FieldType.STRING,\n",
    "          method=GenerationMethod.GENERATE,\n",
    "          description=\"A one-paragraph summary\"\n",
    "        ),\n",
    "        \"Sentiment\": FieldDefinition(\n",
    "          type=FieldType.STRING,\n",
    "          method=GenerationMethod.CLASSIFY,\n",
    "          description=\"Overall sentiment\",\n",
    "          enum=[\n",
    "            \"Positive\",\n",
    "            \"Neutral\",\n",
    "            \"Negative\"\n",
    "          ]\n",
    "        )\n",
    "      }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the analyzer\n",
    "print(f\"üîß Creating custom analyzer '{conversation_analyzer_id}'...\")\n",
    "response = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=conversation_analyzer_id,\n",
    "    resource=conversation_analyzer\n",
    ")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"‚è≥ Waiting for analyzer creation to complete...\")\n",
    "await response.result()\n",
    "print(f\"‚úÖ Analyzer '{conversation_analyzer_id}' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sample file\n",
    "audio_path = sample_file_path = '../data/callCenterRecording.mp3'\n",
    "print(f\"üìÑ Reading audio file: {audio_path}\")\n",
    "with open(audio_path, \"rb\") as audio_file:\n",
    "    audio_content = audio_file.read()\n",
    "\n",
    "# Begin audio analysis operation\n",
    "print(f\"üîç Starting audio analysis with analyzer '{conversation_analyzer_id}'...\")\n",
    "analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=conversation_analyzer_id,\n",
    "    input=audio_content,\n",
    "    content_type=\"application/octet-stream\",\n",
    ")\n",
    "\n",
    "# Wait for analysis completion\n",
    "print(f\"‚è≥ Waiting for audio analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(f\"‚úÖ Audio analysis completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result\n",
    "analysis_operation_id = extract_operation_id_from_poller(\n",
    "    analysis_poller, PollerType.ANALYZE_CALL\n",
    ")\n",
    "print(f\"üìã Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "# Get the analysis result using the operation ID\n",
    "print(\n",
    "    f\"üîç Getting analysis result using operation ID '{analysis_operation_id}'...\"\n",
    ")\n",
    "operation_status = await client.content_analyzers.get_result(\n",
    "    operation_id=analysis_operation_id,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Analysis result retrieved successfully!\")\n",
    "print(f\"   Operation ID: {operation_status.id}\")\n",
    "print(f\"   Status: {operation_status.status}\")\n",
    "\n",
    "# The actual analysis result is in operation_status.result\n",
    "operation_result = operation_status.result\n",
    "if operation_result is None:\n",
    "    print(\"‚ö†Ô∏è  No analysis result available\")\n",
    "\n",
    "print(f\"   Result contains {len(operation_result.contents)} contents\")\n",
    "\n",
    "# Save the analysis result to a file\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=operation_result.as_dict(),\n",
    "    filename_prefix=\"conversation_analyzers_get_result\",\n",
    ")\n",
    "print(f\"üíæ Analysis result saved to: {saved_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversational audio analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(operation_result.as_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up conversational audio analyzer\n",
    "\n",
    "Note: In production environments, you would typically keep analyzers for reuse rather than deleting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üóëÔ∏è  Deleting analyzer '{conversation_analyzer_id}' (demo cleanup)...\")\n",
    "await client.content_analyzers.delete(analyzer_id=conversation_analyzer_id)\n",
    "print(f\"‚úÖ Analyzer '{conversation_analyzer_id}' deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Analysis\n",
    "\n",
    "Now let's explore video analysis capabilities. This modality can extract insights from video content including descriptions, sentiment analysis, and key scene identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Marketing Video Analysis\n",
    "\n",
    "Let's analyze a marketing video to extract descriptions, sentiment, and key insights that could be valuable for content understanding and marketing analytics.\n",
    "\n",
    "Content Understanding offers three ways to slice a video, letting you get the output you need for whole videos or short clips. You can use these options by setting the `segmentationMode` property on a custom analyzer.\n",
    "- Whole-video ‚Äì `\"segmentationMode\": \"noSegmentation\"` The service treats the entire video file as a single segment and extracts metadata across its full duration.  \n",
    "  Example:\n",
    "    - Compliance checks that look for specific brand-safety issues anywhere in an ad\n",
    "    - full-length descriptive summaries\n",
    "- Automatic segmentation ‚Äì `\"segmentationMode\": \"auto\"` The service analyzes the timeline and breaks it up for you. Groups successive shots into coherent scenes, capped at one minute each.  \n",
    "  Example:\n",
    "    - Create storyboards from a show\n",
    "    - Inserting mid-roll ads at logical pauses.\n",
    "- Custom segmentation ‚Äì `\"segmentationMode\": \"custom\"` You describe the logic in natural language and the model creates segments to match. Set `segmentationDefinition` with a string describing how you'd like the video to be segmented. Custom allows segments of varying length from seconds to minutes depending on the prompt.  \n",
    "  Example:\n",
    "    - Break a news broadcast up into stories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1 Analyze without Segmentation\n",
    "\n",
    "In this example, we analyze a marketing video without segmentation.\n",
    "- Please set `segmentationMode` to `noSegmentation` in the analyzer schema `config` to process the entire video as one segment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run marketing video analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_analyzer_id = \"marketing-video-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "# Create a custom analyzer using object model\n",
    "print(f\"üîß Creating custom analyzer '{video_analyzer_id}'...\")\n",
    "video_content_analyzer = ContentAnalyzer(\n",
    "    description=\"Sample marketing video analytics\",\n",
    "    base_analyzer_id=\"prebuilt-videoAnalyzer\",\n",
    "    config=ContentAnalyzerConfig(\n",
    "        return_details=True,\n",
    "        segmentation_mode=SegmentationMode.NO_SEGMENTATION\n",
    "    ),\n",
    "    field_schema=FieldSchema(\n",
    "        fields={\n",
    "            \"Description\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                description=\"Detailed summary of the video segment, focusing on product characteristics, lighting, and color palette.\"\n",
    "            ),\n",
    "            \"Sentiment\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=GenerationMethod.CLASSIFY,\n",
    "                enum=[\n",
    "                    \"Positive\",\n",
    "                    \"Neutral\",\n",
    "                    \"Negative\"\n",
    "                ]\n",
    "            )\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Start the analyzer creation operation\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=video_analyzer_id,\n",
    "    resource=video_content_analyzer,\n",
    ")\n",
    "\n",
    "# Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"üìã Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"‚è≥ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"‚úÖ Analyzer '{video_analyzer_id}' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sample video file\n",
    "video_path = '../data/FlightSimulator.mp4'\n",
    "print(f\"üìÑ Reading video file: {video_path}\")\n",
    "with open(video_path, \"rb\") as video_file:\n",
    "    video_content = video_file.read()\n",
    "\n",
    "# Begin video analysis operation\n",
    "print(f\"üîç Starting video analysis with analyzer '{video_analyzer_id}'...\")\n",
    "analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=video_analyzer_id,\n",
    "    input=video_content,\n",
    "    content_type=\"application/octet-stream\",\n",
    ")\n",
    "\n",
    "# Wait for analysis completion\n",
    "print(f\"‚è≥ Waiting for video analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(f\"‚úÖ Video analysis completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result\n",
    "analysis_operation_id = extract_operation_id_from_poller(\n",
    "    analysis_poller, PollerType.ANALYZE_CALL\n",
    ")\n",
    "print(f\"üìã Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "# Get the analysis result using the operation ID\n",
    "print(\n",
    "    f\"üîç Getting analysis result using operation ID '{analysis_operation_id}'...\"\n",
    ")\n",
    "operation_status = await client.content_analyzers.get_result(\n",
    "    operation_id=analysis_operation_id,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Analysis result retrieved successfully!\")\n",
    "print(f\"   Operation ID: {operation_status.id}\")\n",
    "print(f\"   Status: {operation_status.status}\")\n",
    "\n",
    "# The actual analysis result is in operation_status.result\n",
    "operation_result = operation_status.result\n",
    "if operation_result is None:\n",
    "    print(\"‚ö†Ô∏è  No analysis result available\")\n",
    "\n",
    "print(f\"   Result contains {len(operation_result.contents)} contents\")\n",
    "\n",
    "# Save the analysis result to a file\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=operation_result.as_dict(),\n",
    "    filename_prefix=\"video_content_analyzers_get_result\",\n",
    ")\n",
    "print(f\"üíæ Analysis result saved to: {saved_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marketing video analysis result\n",
    "- The result is generated from the content of the entire video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(operation_result.as_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up marketing video analyzer\n",
    "\n",
    "Note: In production environments, you would typically keep analyzers for reuse rather than deleting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üóëÔ∏è  Deleting analyzer '{video_analyzer_id}' (demo cleanup)...\")\n",
    "await client.content_analyzers.delete(analyzer_id=video_analyzer_id)\n",
    "print(f\"‚úÖ Analyzer '{video_analyzer_id}' deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2 Analyze With Automatic Segmentation\n",
    "\n",
    "In this example, we use automatic segmentation for marketing video analytics.  \n",
    "- Please set `segmentationMode` to `auto` in the analyzer schema `config` to enable automatic segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run marketing video analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_analyzer_id = \"marketing-video-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "# Create a custom analyzer using object model\n",
    "print(f\"üîß Creating custom analyzer '{video_analyzer_id}'...\")\n",
    "\n",
    "video_content_analyzer = ContentAnalyzer(\n",
    "    description=\"Sample marketing video analytics\",\n",
    "    base_analyzer_id=\"prebuilt-videoAnalyzer\",\n",
    "    config=ContentAnalyzerConfig(\n",
    "        return_details=True,\n",
    "        segmentation_mode=SegmentationMode.NO_SEGMENTATION\n",
    "    ),\n",
    "    field_schema=FieldSchema(\n",
    "        fields={\n",
    "            \"Segments\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.OBJECT,\n",
    "                    properties={\n",
    "                        \"Description\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            description=\"Detailed summary of the video segment, focusing on product characteristics, lighting, and color palette.\"\n",
    "                        ),\n",
    "                        \"Sentiment\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.CLASSIFY,\n",
    "                            enum=[\n",
    "                                \"Positive\",\n",
    "                                \"Neutral\",\n",
    "                                \"Negative\"\n",
    "                            ]\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Start the analyzer creation operation\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=video_analyzer_id,\n",
    "    resource=video_content_analyzer,\n",
    ")\n",
    "\n",
    "# Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"üìã Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"‚è≥ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"‚úÖ Analyzer '{video_analyzer_id}' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_path = '../data/FlightSimulator.mp4'\n",
    "\n",
    "print(f\"üìÑ Reading video file: {video_path}\")\n",
    "with open(video_path, \"rb\") as video_file:\n",
    "    video_content = video_file.read()\n",
    "\n",
    "# Begin video analysis operation\n",
    "print(f\"üîç Starting video analysis with analyzer '{video_analyzer_id}'...\")\n",
    "analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=video_analyzer_id,\n",
    "    input=video_content,\n",
    "    content_type=\"application/octet-stream\",\n",
    ")\n",
    "\n",
    "# Wait for analysis completion\n",
    "print(f\"‚è≥ Waiting for video analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(f\"‚úÖ Video analysis completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result\n",
    "analysis_operation_id = extract_operation_id_from_poller(\n",
    "    analysis_poller, PollerType.ANALYZE_CALL\n",
    ")\n",
    "print(f\"üìã Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "# Get the analysis result using the operation ID\n",
    "print(\n",
    "    f\"üîç Getting analysis result using operation ID '{analysis_operation_id}'...\"\n",
    ")\n",
    "operation_status = await client.content_analyzers.get_result(\n",
    "    operation_id=analysis_operation_id,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Analysis result retrieved successfully!\")\n",
    "print(f\"   Operation ID: {operation_status.id}\")\n",
    "print(f\"   Status: {operation_status.status}\")\n",
    "\n",
    "# The actual analysis result is in operation_status.result\n",
    "operation_result = operation_status.result\n",
    "if operation_result is None:\n",
    "    print(\"‚ö†Ô∏è  No analysis result available\")\n",
    "\n",
    "print(f\"   Result contains {len(operation_result.contents)} contents\")\n",
    "\n",
    "# Save the analysis result to a file\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=operation_result.as_dict(),\n",
    "    filename_prefix=\"video_content_analyzers_get_result\",\n",
    ")\n",
    "print(f\"üíæ Analysis result saved to: {saved_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marketing video analysis result\n",
    "- The output includes automatically segmented clips with descriptions in the markdown content.  \n",
    "- The analyzer generates the fields defined in the schema separately for each segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(operation_result.as_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up marketing video analyzer\n",
    "\n",
    "Note: In production environments, you would typically keep analyzers for reuse rather than deleting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üóëÔ∏è  Deleting analyzer '{video_analyzer_id}' (demo cleanup)...\")\n",
    "await client.content_analyzers.delete(analyzer_id=video_analyzer_id)\n",
    "print(f\"‚úÖ Analyzer '{video_analyzer_id}' deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3 Analyze With Custom Segmentation\n",
    "\n",
    "In this example, we use custom segmentation for marketing video analytics.  \n",
    "- Please set `segmentationMode` to `custom`.  \n",
    "- Provide a `segmentationDefinition` string describing how you would like the video to be segmented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run marketing video analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_analyzer_id = \"marketing-video-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "# Create a custom analyzer using object model\n",
    "print(f\"üîß Creating custom analyzer '{video_analyzer_id}'...\")\n",
    "\n",
    "video_content_analyzer = ContentAnalyzer(\n",
    "    description=\"Sample marketing video analytics\",\n",
    "    base_analyzer_id=\"prebuilt-videoAnalyzer\",\n",
    "    config=ContentAnalyzerConfig(\n",
    "        return_details=True,\n",
    "        segmentation_mode=SegmentationMode.NO_SEGMENTATION,\n",
    "        segmentation_definition=\"Segment the video at each clear narrative or visual transition that introduces a new marketing message, speaker, or brand moment. Segments should begin when there is a change in speaker, a shift in visual theme (e.g., logos, product shots, data center views, simulation footage, aircraft scenes), or the introduction of a new key message (e.g., quality of data, scale of infrastructure, customer benefit, real-world aviation use). Each segment should capture one distinct marketing idea or value point, ending when the focus transitions to the next theme.\"\n",
    "    ),\n",
    "    field_schema=FieldSchema(\n",
    "        fields={\n",
    "            \"Segments\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.OBJECT,\n",
    "                    properties={\n",
    "                        \"Description\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            description=\"Detailed summary of the video segment, focusing on product characteristics, lighting, and color palette.\"\n",
    "                        ),\n",
    "                        \"Sentiment\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.CLASSIFY,\n",
    "                            enum=[\n",
    "                                \"Positive\",\n",
    "                                \"Neutral\",\n",
    "                                \"Negative\"\n",
    "                            ]\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Start the analyzer creation operation\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=video_analyzer_id,\n",
    "    resource=video_content_analyzer,\n",
    ")\n",
    "\n",
    "# Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"üìã Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"‚è≥ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"‚úÖ Analyzer '{video_analyzer_id}' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_path = '../data/FlightSimulator.mp4'\n",
    "\n",
    "print(f\"üìÑ Reading video file: {video_path}\")\n",
    "with open(video_path, \"rb\") as video_file:\n",
    "    video_content = video_file.read()\n",
    "\n",
    "# Begin video analysis operation\n",
    "print(f\"üîç Starting video analysis with analyzer '{video_analyzer_id}'...\")\n",
    "analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=video_analyzer_id,\n",
    "    input=video_content,\n",
    "    content_type=\"application/octet-stream\",\n",
    ")\n",
    "\n",
    "# Wait for analysis completion\n",
    "print(f\"‚è≥ Waiting for video analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(f\"‚úÖ Video analysis completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result\n",
    "analysis_operation_id = extract_operation_id_from_poller(\n",
    "    analysis_poller, PollerType.ANALYZE_CALL\n",
    ")\n",
    "print(f\"üìã Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "# Get the analysis result using the operation ID\n",
    "print(\n",
    "    f\"üîç Getting analysis result using operation ID '{analysis_operation_id}'...\"\n",
    ")\n",
    "operation_status = await client.content_analyzers.get_result(\n",
    "    operation_id=analysis_operation_id,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Analysis result retrieved successfully!\")\n",
    "print(f\"   Operation ID: {operation_status.id}\")\n",
    "print(f\"   Status: {operation_status.status}\")\n",
    "\n",
    "# The actual analysis result is in operation_status.result\n",
    "operation_result = operation_status.result\n",
    "if operation_result is None:\n",
    "    print(\"‚ö†Ô∏è  No analysis result available\")\n",
    "\n",
    "print(f\"   Result contains {len(operation_result.contents)} contents\")\n",
    "\n",
    "# Save the analysis result to a file\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=operation_result.as_dict(),\n",
    "    filename_prefix=\"video_content_analyzers_get_result\",\n",
    ")\n",
    "print(f\"üíæ Analysis result saved to: {saved_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marketing video analysis result\n",
    "- The video is segmented according to your custom definition, with segment descriptions included in the markdown content.  \n",
    "- The segmentation may differ from automatic segmentation results.  \n",
    "- The analyzer generates the fields defined in the schema separately for each segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(operation_result.as_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up marketing video analyzer\n",
    "\n",
    "Note: In production environments, you would typically keep analyzers for reuse rather than deleting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üóëÔ∏è  Deleting analyzer '{video_analyzer_id}' (demo cleanup)...\")\n",
    "await client.content_analyzers.delete(analyzer_id=video_analyzer_id)\n",
    "print(f\"‚úÖ Analyzer '{video_analyzer_id}' deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis\n",
    "\n",
    "Finally, let's explore image analysis capabilities. This modality can extract information from charts, diagrams, and other visual content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Chart and Image Analysis\n",
    "\n",
    "Let's analyze a chart image to extract data points, trends, and insights from visual data representations. \\\n",
    "Create and run chart image analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_analyzer_id = \"chart-analysis-\" + str(uuid.uuid4())\n",
    "\n",
    "# Create a custom analyzer using object model\n",
    "print(f\"üîß Creating custom analyzer '{chart_analyzer_id}'...\")\n",
    "\n",
    "chart_content_analyzer = ContentAnalyzer(\n",
    "    base_analyzer_id=\"prebuilt-imageAnalyzer\",\n",
    "    description=\"Extract detailed structured information from charts and diagrams.\",\n",
    "    config=ContentAnalyzerConfig(\n",
    "        return_details=False,\n",
    "    ),\n",
    "    field_schema=FieldSchema(\n",
    "        name=\"ChartAndDiagram\",\n",
    "        description=\"Structured information from charts and diagrams.\",\n",
    "        fields={\n",
    "            \"Title\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"Verbatim title of the chart.\"\n",
    "            ),\n",
    "            \"ChartType\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=GenerationMethod.CLASSIFY,\n",
    "                description=\"The type of chart.\",\n",
    "                enum=[\n",
    "                    \"area\",\n",
    "                    \"bar\",\n",
    "                    \"box\",\n",
    "                    \"bubble\",\n",
    "                    \"candlestick\",\n",
    "                    \"funnel\",\n",
    "                    \"heatmap\",\n",
    "                    \"histogram\",\n",
    "                    \"line\",\n",
    "                    \"pie\",\n",
    "                    \"radar\",\n",
    "                    \"rings\",\n",
    "                    \"rose\",\n",
    "                    \"treemap\"\n",
    "                ],\n",
    "                enum_descriptions={\n",
    "                    \"histogram\": \"Continuous values on the x-axis, which distinguishes it from bar.\",\n",
    "                    \"rose\": \"In contrast to pie charts, the sectors are of equal angles and differ in how far each sector extends from the center of the circle.\"\n",
    "                },\n",
    "            ),\n",
    "            \"TopicKeywords\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"Relevant topics associated with the chart, used for tagging.\",\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.STRING,\n",
    "                    method=GenerationMethod.GENERATE,\n",
    "                    examples=[\n",
    "                        \"Business and finance\",\n",
    "                        \"Arts and culture\",\n",
    "                        \"Education and academics\"\n",
    "                    ]\n",
    "                )\n",
    "            ),\n",
    "            \"DetailedDescription\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"Detailed description of the chart or diagram, not leaving out any key information. Include numbers, trends, and other details.\"\n",
    "            ),\n",
    "            \"Summary\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"Detailed summary of the chart, including highlights and takeaways.\"\n",
    "            ),\n",
    "            \"MarkdownDataTable\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"Underlying data of the chart in tabular markdown format. Give markdown output with valid syntax and accurate numbers, and fill any uncertain values with empty cells. If not applicable, output an empty string.\"\n",
    "            ),\n",
    "            \"AxisTitles\": FieldDefinition(\n",
    "                type=FieldType.OBJECT,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"Titles of the axes.\",\n",
    "                properties={\n",
    "                    \"xAxisTitle\": FieldDefinition(\n",
    "                        type=FieldType.STRING,\n",
    "                        method=GenerationMethod.GENERATE,\n",
    "                        description=\"Title of the x-axis.\"\n",
    "                    ),\n",
    "                    \"yAxisTitle\": FieldDefinition(\n",
    "                        type=FieldType.STRING,\n",
    "                        method=GenerationMethod.GENERATE,\n",
    "                        description=\"Title of the y-axis.\"\n",
    "                    )\n",
    "                }\n",
    "            ),\n",
    "            \"FootnotesAndAnnotations\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"All footnotes and textual annotations in the chart or diagram.\"\n",
    "            )\n",
    "        },\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Start the analyzer creation operation\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=chart_analyzer_id,\n",
    "    resource=chart_content_analyzer,\n",
    ")\n",
    "\n",
    "# Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"üìã Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"‚è≥ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"‚úÖ Analyzer '{chart_analyzer_id}' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Failed\n",
    "# Error Code: analysis_result = await analysis_poller.result()\n",
    "# Inner error: {\n",
    "#     \"code\": \"ServiceUnavailable\",\n",
    "#     \"message\": \"The service is currently unavailable. Please try again later.\"\n",
    "# }\n",
    "\n",
    "sample_file_path = '../data/pieChart.jpg'\n",
    "print(f\"üìÑ Reading document file: {sample_file_path}\")\n",
    "with open(sample_file_path, \"rb\") as f:\n",
    "    chart_content = f.read()\n",
    "\n",
    "# Check if this is a Git LFS pointer file\n",
    "analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=chart_analyzer_id,\n",
    "    input=chart_content,\n",
    "    content_type=\"application/octet-stream\",\n",
    ")\n",
    "\n",
    "# Wait for analysis completion\n",
    "print(f\"‚è≥ Waiting for document analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(f\"‚úÖ Document analysis completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result\n",
    "analysis_operation_id = extract_operation_id_from_poller(\n",
    "    analysis_poller, PollerType.ANALYZE_CALL\n",
    ")\n",
    "print(f\"üìã Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "# Get the analysis result using the operation ID\n",
    "print(\n",
    "    f\"üîç Getting analysis result using operation ID '{analysis_operation_id}'...\"\n",
    ")\n",
    "operation_status = await client.content_analyzers.get_result(\n",
    "    operation_id=analysis_operation_id,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Analysis result retrieved successfully!\")\n",
    "print(f\"   Operation ID: {operation_status.id}\")\n",
    "print(f\"   Status: {operation_status.status}\")\n",
    "\n",
    "# The actual analysis result is in operation_status.result\n",
    "operation_result = operation_status.result\n",
    "if operation_result is None:\n",
    "    print(\"‚ö†Ô∏è  No analysis result available\")\n",
    "\n",
    "print(f\"   Result contains {len(operation_result.contents)} contents\")\n",
    "\n",
    "# Save the analysis result to a file\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=operation_result.as_dict(),\n",
    "    filename_prefix=\"content_analyzers_get_result\",\n",
    ")\n",
    "print(f\"üíæ Analysis result saved to: {saved_file_path}\")\n",
    "\n",
    "# Save the analysis result to a file\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=operation_result.as_dict(),\n",
    "    filename_prefix=\"content_analyzers_get_result\",\n",
    ")\n",
    "print(f\"üíæ Analysis result saved to: {saved_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chart analysis result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(operation_result.as_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up chart image analyzer\n",
    "\n",
    "Note: In production environments, you would typically keep analyzers for reuse rather than deleting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üóëÔ∏è  Deleting analyzer '{chart_analyzer_id}' (demo cleanup)...\")\n",
    "await client.content_analyzers.delete(analyzer_id=chart_analyzer_id)\n",
    "print(f\"‚úÖ Analyzer '{chart_analyzer_id}' deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "üéâ **Congratulations!** You've successfully explored all the major modalities of Azure AI Content Understanding:\n",
    "\n",
    "‚úÖ **Document Analysis**: Extracted fields from invoices and receipts  \n",
    "‚úÖ **Audio Analysis**: Analyzed call recordings and conversational audio  \n",
    "‚úÖ **Video Analysis**: Processed marketing videos for insights  \n",
    "‚úÖ **Image Analysis**: Extracted information from charts and visual content\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Multi-modal capabilities**: Content Understanding can process documents, audio, video, and images\n",
    "- **Customizable templates**: Each analyzer template is designed for specific use cases but can be customized\n",
    "- **Automatic cleanup**: Each analyzer was automatically cleaned up after use to manage resources\n",
    "- **Structured output**: All results are returned in consistent JSON format for easy integration\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore the analyzer templates in the `../analyzer_templates/` directory\n",
    "- Modify existing templates or create custom ones for your specific use cases\n",
    "- Check out other notebooks in this repository for advanced scenarios\n",
    "- Visit the [Azure AI Content Understanding documentation](https://docs.microsoft.com/azure/ai-services/content-understanding/) for more information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
