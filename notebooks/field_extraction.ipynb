{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Custom Fields from Your File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use analyzers to extract custom fields from your input files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "1. Ensure the Azure AI service is configured by following the [configuration steps](../README.md#configure-azure-ai-service-resource).\n",
    "2. Install the required packages to run this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure AI Content Understanding Client\n",
    "\n",
    "> The [AzureContentUnderstandingClient](../python/content_understanding_client.py) is a utility class providing functions to interact with the Content Understanding API. Prior to the official release of the Content Understanding SDK, it serves as a lightweight SDK. Fill in the constants **AZURE_AI_ENDPOINT**, **AZURE_AI_API_VERSION**, and **AZURE_AI_API_KEY** with your Azure AI Service credentials.\n",
    "\n",
    "> ⚠️ Important:\n",
    "Update the sections below to match your Azure authentication method.\n",
    "Look for the `# IMPORTANT` comments and modify those parts accordingly.\n",
    "Skipping this step may cause the sample to fail.\n",
    "\n",
    "> ⚠️ Note: Using a subscription key works, but using a token provider with Azure Active Directory (AAD) is more secure and highly recommended for production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# For authentication, you can use either token-based auth or subscription key; only one is required\n",
    "AZURE_AI_ENDPOINT = os.getenv(\"AZURE_AI_ENDPOINT\")\n",
    "# IMPORTANT: Replace with your actual subscription key or set it in your \".env\" file if not using token auth\n",
    "AZURE_AI_API_KEY = os.getenv(\"AZURE_AI_API_KEY\")\n",
    "AZURE_AI_API_VERSION = os.getenv(\"AZURE_AI_API_VERSION\", \"2025-05-01-preview\")\n",
    "\n",
    "# Add the parent directory to the path to use shared modules\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "from python.content_understanding_client import AzureContentUnderstandingClient\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = AzureContentUnderstandingClient(\n",
    "    endpoint=AZURE_AI_ENDPOINT,\n",
    "    api_version=AZURE_AI_API_VERSION,\n",
    "    # IMPORTANT: Comment out token_provider if using subscription key\n",
    "    token_provider=token_provider,\n",
    "    # IMPORTANT: Uncomment this if using subscription key\n",
    "    # subscription_key=AZURE_AI_API_KEY,\n",
    "    x_ms_useragent=\"azure-ai-content-understanding-python/field_extraction\",  # This header is used for sample usage telemetry; comment out this line if you want to opt out.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates field extraction across multiple modalities using Azure AI Content Understanding. We'll walk through each modality step by step:\n",
    "\n",
    "1. **Document Analysis** - Extract fields from invoices and receipts\n",
    "2. **Audio Analysis** - Process call recordings and conversational audio\n",
    "3. **Video Analysis** - Analyze marketing videos and extract insights\n",
    "4. **Image Analysis** - Extract information from charts and images\n",
    "\n",
    "Each section will create an analyzer, process sample data, display results, and clean up the analyzer before moving on to the next modality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Analyzer Templates and Schemas\n",
    "\n",
    "Before creating our first analyzer, it's important to understand the structure and schema of analyzer templates. Custom analyzers in Azure AI Content Understanding are defined using JSON templates that specify which fields to extract and how to process the content.\n",
    "\n",
    "**Key Schema Components:**\n",
    "\n",
    "- **`baseAnalyzerId`**: Specifies which prebuilt analyzer to derive from (e.g., `prebuilt-documentAnalyzer`, `prebuilt-audioAnalyzer`, `prebuilt-videoAnalyzer`, `prebuilt-imageAnalyzer`, `prebuilt-callCenter`). This provides foundational capabilities for your custom analyzer.\n",
    "\n",
    "- **`fields`**: Define specific data points to extract. Each field has:\n",
    "  - **Field name**: The identifier for the extracted data (required and important for referencing results).\n",
    "  - **Description**: Optional but helpful for documentation and understanding the field's purpose.\n",
    "  - **Method**: `\"extract\"` (for extracting existing information from documents - currently available only for document analysis) or `\"generate\"` (for generating new insights using AI).\n",
    "\n",
    "- **`method`**: The overall extraction approach - use `\"extract\"` for standard field extraction from documents or `\"generate\"` when leveraging AI to generate insights or summaries.\n",
    "\n",
    "**Important Note:** The `\"extract\"` method is currently supported only for document analysis (`prebuilt-documentAnalyzer`). For audio, video, and image modalities, use the `\"generate\"` method.\n",
    "\n",
    "Let's take a look at the invoice template to see these concepts in action:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the schema for the document modality used to extract fields from an invoice PDF. This analyzer identifies key invoice elements such as vendor information, amounts, dates, and line items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "analyzer_template_path = '../analyzer_templates/invoice.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of the schema for the video modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/marketing_video.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Analysis\n",
    "\n",
    "Let's begin with document analysis by extracting fields from invoices and receipts. This modality is ideal for processing structured documents and extracting key information like amounts, dates, vendor details, and line items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Invoice Field Extraction\n",
    "\n",
    "Extract fields from an invoice PDF. This analyzer detects essential invoice elements such as vendor information, amounts, dates, and line items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/invoice.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Invoice Analyzer**\n",
    "\n",
    "Now, let's create the invoice analyzer and process our sample invoice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/invoice.pdf'\n",
    "invoice_analyzer_id = \"invoice-extraction-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating invoice analyzer: {invoice_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(invoice_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Invoice analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing invoice: {sample_file_path}\")\n",
    "response = client.begin_analyze(invoice_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invoice Analysis Results**\n",
    "\n",
    "Let's examine the extracted fields from the invoice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Invoice Analyzer**\n",
    "\n",
    "Clean up the analyzer to manage resources. In production, you would typically keep analyzers for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(invoice_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Invoice Field Extraction with Source Grounding\n",
    "\n",
    "Now, let's analyze the same invoice with enhanced field source information and confidence scores. This provides additional context about where each extracted field was found in the document.\n",
    "\n",
    "**Note**: This custom analyzer is for demonstration purposes only. In production, users should start from `prebuilt-invoice` for invoice processing.\n",
    "\n",
    "**Key Feature**: This analyzer template uses `estimateFieldSourceAndConfidence: true` in the configuration, which enables the service to provide detailed information about:\n",
    "- **Field source locations**: Exact coordinates and bounding boxes where each field was found\n",
    "- **Confidence scores**: The confidence level for each extracted field\n",
    "- **Enhanced metadata**: Additional context about the extraction process\n",
    "\n",
    "This is particularly beneficial for applications that need to verify extraction accuracy or provide visual feedback indicating where information was sourced in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/invoice_field_source.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Invoice Field Source Analyzer**\n",
    "\n",
    "Let's create the enhanced analyzer and process the invoice with source grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/invoice.pdf'\n",
    "invoice_source_analyzer_id = \"invoice-field-source-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating invoice field source analyzer: {invoice_source_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(invoice_source_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Invoice field source analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing invoice with field source: {sample_file_path}\")\n",
    "response = client.begin_analyze(invoice_source_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invoice Field Source Analysis Results**\n",
    "\n",
    "Review the enhanced results, which include detailed field source locations and confidence scores. Pay special attention to the `confidence` and `source` attributes for each extracted field. The `source` attribute specifies the page number and bounding box coordinates, offering precise context for verification and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Invoice Field Source Analyzer**\n",
    "\n",
    "Clean up the field source analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(invoice_source_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Receipt Field Extraction\n",
    "\n",
    "Extract information from a receipt image. This demonstrates how the Content Understanding service can handle different document types and formats.\n",
    "\n",
    "**Receipt Analyzer Template**\n",
    "\n",
    "Let's examine the receipt analyzer template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/receipt.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Receipt Analyzer**\n",
    "\n",
    "Now, let's create the receipt analyzer and process our sample receipt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/receipt.png'\n",
    "receipt_analyzer_id = \"receipt-extraction-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating receipt analyzer: {receipt_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(receipt_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Receipt analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing receipt: {sample_file_path}\")\n",
    "response = client.begin_analyze(receipt_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Receipt Analysis Results**\n",
    "\n",
    "Let's examine the extracted fields from the receipt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Receipt Analyzer**\n",
    "\n",
    "Clean up the receipt analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(receipt_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Analysis\n",
    "\n",
    "Now, let's move on to audio analysis. This modality allows extraction of insights from audio files such as call recordings, including summaries, sentiment analysis, topic identification, and entity extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Call Recording Analytics\n",
    "\n",
    "Analyze a call center recording to extract insights such as summary, topics discussed, companies mentioned, and people involved in the conversation.\n",
    "\n",
    "**Call Recording Analytics Template**\n",
    "\n",
    "Let's examine the call recording analytics template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/call_recording_analytics.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run the call recording analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/callCenterRecording.mp3'\n",
    "call_analyzer_id = \"call-recording-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating call recording analyzer: {call_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(call_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Call recording analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing call recording: {sample_file_path}\")\n",
    "print(\"⏳ Note: Audio analysis may take longer than document analysis...\")\n",
    "response = client.begin_analyze(call_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call recording analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up call recording analyzer.\n",
    "\n",
    "Note: In production environments, you would typically keep analyzers for reuse rather than deleting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(call_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conversational Audio Analytics\n",
    "\n",
    "Analyze the same audio file focusing on conversational aspects like sentiment analysis and dialogue understanding.\n",
    "\n",
    "Conversational audio analytics template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/conversational_audio_analytics.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run the conversational audio analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/callCenterRecording.mp3'\n",
    "conversation_analyzer_id = \"conversational-audio-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating conversational audio analyzer: {conversation_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(conversation_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Conversational audio analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing conversational audio: {sample_file_path}\")\n",
    "print(\"⏳ Note: Audio analysis may take longer than document analysis...\")\n",
    "response = client.begin_analyze(conversation_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversational audio analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up conversational audio analyzer.\n",
    "\n",
    "Note: In production environments, you would typically keep analyzers for reuse rather than deleting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(conversation_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Analysis\n",
    "\n",
    "Explore video analysis capabilities. This modality extracts insights from video content including descriptions, sentiment analysis, and key scene identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Marketing Video Analysis\n",
    "\n",
    "Analyze a marketing video to extract descriptions, sentiment, and key insights valuable for content understanding and marketing analytics.\n",
    "\n",
    "Marketing video analytics template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/marketing_video.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run the marketing video analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/FlightSimulator.mp4'\n",
    "video_analyzer_id = \"marketing-video-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating marketing video analyzer: {video_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(video_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Marketing video analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing marketing video: {sample_file_path}\")\n",
    "print(\"⏳ Note: Video analysis may take significantly longer than document analysis...\")\n",
    "response = client.begin_analyze(video_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up marketing video analyzer.\n",
    "\n",
    "Note: In production environments, you would typically keep analyzers for reuse rather than deleting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(video_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis\n",
    "\n",
    "Finally, explore image analysis capabilities. This modality extracts information from charts, diagrams, and other visual content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Chart and Image Analysis\n",
    "\n",
    "Analyze a chart image to extract data points, trends, and insights from visual data representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image chart analytics template\n",
    "analyzer_template_path = '../analyzer_templates/image_chart.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/pieChart.jpg'\n",
    "chart_analyzer_id = \"chart-analysis-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating chart analyzer: {chart_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(chart_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Chart analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing chart: {sample_file_path}\")\n",
    "response = client.begin_analyze(chart_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(chart_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "🎉 **Congratulations!** You have successfully explored the major modalities of Azure AI Content Understanding:\n",
    "\n",
    "✅ **Document Analysis**: Extracted fields from invoices and receipts\n",
    "✅ **Audio Analysis**: Analyzed call recordings and conversational audio\n",
    "✅ **Video Analysis**: Processed marketing videos for insights\n",
    "✅ **Image Analysis**: Extracted information from charts and visual content\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Multi-modal capabilities**: Content Understanding can process documents, audio, video, and images.\n",
    "- **Customizable templates**: Each analyzer template is designed for specific use cases but can be customized.\n",
    "- **Automatic cleanup**: Each analyzer was cleaned up after use to manage resources.\n",
    "- **Structured output**: All results are returned as consistent JSON for easy integration.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore the analyzer templates in the `../analyzer_templates/` directory.\n",
    "- Modify existing templates or create custom ones for your specific use cases.\n",
    "- Check other notebooks in this repository for advanced scenarios.\n",
    "- Visit the [Azure AI Content Understanding documentation](https://docs.microsoft.com/azure/ai-services/content-understanding/) for more information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}