{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Custom Fields from Your File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use analyzers to extract custom fields from your input files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "1. Please ensure your Azure AI service is configured by following the [configuration steps](../README.md#configure-azure-ai-service-resource).\n",
    "2. Please install the required packages to run this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure AI Content Understanding Client\n",
    "\n",
    "> The [AzureContentUnderstandingClient](../python/content_understanding_client.py) is a utility class providing functions to interact with the Content Understanding API. Before the official release of the Content Understanding SDK, it acts as a lightweight SDK. Please fill in the constants **AZURE_AI_ENDPOINT** and **AZURE_AI_API_VERSION** with your Azure AI Service information. Optionally, you may provide **AZURE_AI_API_KEY** if your setup requires key-based authentication.\n",
    "\n",
    "> ⚠️ Important:\n",
    "Please update the code below to match your Azure authentication method.\n",
    "Look for the `# IMPORTANT` comments and modify those sections accordingly.\n",
    "Skipping this step may cause the sample to not run correctly.\n",
    "\n",
    "> ⚠️ Note: Using a subscription key works, but using a token provider with Azure Active Directory (AAD) is safer and highly recommended for production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# For authentication, you can use either token-based authentication or a subscription key; only one method is required.\n",
    "AZURE_AI_ENDPOINT = os.getenv(\"AZURE_AI_ENDPOINT\")\n",
    "# IMPORTANT: Replace with your actual subscription key or set it in the \".env\" file if not using token authentication.\n",
    "AZURE_AI_API_KEY = os.getenv(\"AZURE_AI_API_KEY\")\n",
    "AZURE_AI_API_VERSION = os.getenv(\"AZURE_AI_API_VERSION\", \"2025-05-01-preview\")\n",
    "\n",
    "# Add the parent directory to the path to use shared modules\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "from python.content_understanding_client import AzureContentUnderstandingClient\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = AzureContentUnderstandingClient(\n",
    "    endpoint=AZURE_AI_ENDPOINT,\n",
    "    api_version=AZURE_AI_API_VERSION,\n",
    "    # IMPORTANT: Comment out token_provider if using subscription key\n",
    "    token_provider=token_provider,\n",
    "    # IMPORTANT: Uncomment this if using subscription key\n",
    "    # subscription_key=AZURE_AI_API_KEY,\n",
    "    x_ms_useragent=\"azure-ai-content-understanding-python/field_extraction\",  # This header is used for sample usage telemetry; please comment out this line if you wish to opt out.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates field extraction across multiple modalities using Azure AI Content Understanding. We will walk through each modality step-by-step:\n",
    "\n",
    "1. **Document Analysis** - Extract fields from invoices and receipts\n",
    "2. **Audio Analysis** - Process call recordings and conversational audio\n",
    "3. **Video Analysis** - Analyze marketing videos and extract insights\n",
    "4. **Image Analysis** - Extract information from charts and images\n",
    "\n",
    "Each section will create an analyzer, process sample data, display results, and clean up the analyzer before moving on to the next modality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Analyzer Templates and Schemas\n",
    "\n",
    "Before creating our first analyzer, it's important to understand the structure and schema of analyzer templates. Custom analyzers in Azure AI Content Understanding are defined using JSON templates specifying which fields to extract and how to process the content.\n",
    "\n",
    "**Key Schema Components:**\n",
    "\n",
    "- **`baseAnalyzerId`**: Crucial setting that specifies the prebuilt analyzer to derive from (e.g., `prebuilt-documentAnalyzer`, `prebuilt-audioAnalyzer`, `prebuilt-videoAnalyzer`, `prebuilt-imageAnalyzer`, `prebuilt-callCenter`). This provides foundational capabilities for your custom analyzer.\n",
    "\n",
    "- **`fields`**: Defines specific data points to extract. Each field includes:\n",
    "  - **Field name**: Identifier for the extracted data (required and important for referencing results)\n",
    "  - **Description**: Optional but helpful for documentation and understanding the field's purpose\n",
    "  - **Method**: Can be `\"extract\"` (for extracting existing information from documents - currently only available for document analysis) or `\"generate\"` (for generating new insights using AI)\n",
    "\n",
    "- **`method`**: The overall extraction approach - use `\"extract\"` for standard field extraction from documents or `\"generate\"` when AI should generate insights or summaries.\n",
    "\n",
    "**Important Note**: The `\"extract\"` method is currently only available for document analysis (using `prebuilt-documentAnalyzer`). For other modalities such as audio, video, and images, use the `\"generate\"` method.\n",
    "\n",
    "Let's examine the invoice template to see these concepts in action:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following schema defines the document modality analyzer used to extract fields from an invoice PDF. This analyzer identifies key invoice elements such as vendor information, amounts, dates, and line items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/invoice.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example schema for the video modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/marketing_video.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Analysis\n",
    "\n",
    "Let's start with document analysis by extracting fields from invoices and receipts. This modality is ideal for processing structured documents and extracting key information such as amounts, dates, vendor details, and line items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Invoice Field Extraction\n",
    "\n",
    "Let's extract fields from an invoice PDF. This analyzer identifies essential invoice elements such as vendor information, amounts, dates, and line items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/invoice.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Invoice Analyzer**\n",
    "\n",
    "Now, let's create the invoice analyzer and process our sample invoice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/invoice.pdf'\n",
    "invoice_analyzer_id = \"invoice-extraction-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating invoice analyzer: {invoice_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(invoice_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Invoice analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing invoice: {sample_file_path}\")\n",
    "response = client.begin_analyze(invoice_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invoice Analysis Results**\n",
    "\n",
    "Let's examine the extracted fields from the invoice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Invoice Analyzer**\n",
    "\n",
    "Optionally, clean up the analyzer to manage resources (in production, analyzers are typically kept for reuse):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(invoice_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Invoice Field Extraction with Source Grounding\n",
    "\n",
    "Now, let's analyze the same invoice but with enhanced field source information and confidence scores. This provides additional context about the location of each extracted field within the document.\n",
    "\n",
    "**Note**: This custom analyzer is for demonstration purposes only. In production, please start from `prebuilt-invoice` for invoice processing.\n",
    "\n",
    "**Key Feature**: This analyzer template uses `estimateFieldSourceAndConfidence: true` in the 'config', enabling the service to provide detailed information about:\n",
    "- **Field source locations**: Exact coordinates and bounding boxes indicating where each field was found\n",
    "- **Confidence scores**: The confidence level of each extracted field\n",
    "- **Enhanced metadata**: Additional context about the extraction process\n",
    "\n",
    "This feature is particularly useful for applications that require verification of extraction accuracy or visual feedback indicating field locations in the source document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/invoice_field_source.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Invoice Field Source Analyzer**\n",
    "\n",
    "Now, let's create the enhanced analyzer and process the invoice with source grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/invoice.pdf'\n",
    "invoice_source_analyzer_id = \"invoice-field-source-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating invoice field source analyzer: {invoice_source_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(invoice_source_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Invoice field source analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing invoice with field source: {sample_file_path}\")\n",
    "response = client.begin_analyze(invoice_source_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invoice Field Source Analysis Results**\n",
    "\n",
    "Let's review the enhanced results, which include detailed field source locations and confidence scores. Please pay special attention to the `confidence` and `source` attributes for each extracted field. The `source` attribute provides the page number and bounding box coordinates of the extracted data, giving precise context for verification and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Invoice Field Source Analyzer**\n",
    "\n",
    "Optionally, clean up the field source analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(invoice_source_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Receipt Field Extraction\n",
    "\n",
    "Let's extract information from a receipt image. This demonstrates how the Content Understanding service can handle different document types and formats.\n",
    "\n",
    "**Receipt Analyzer Template**\n",
    "\n",
    "Let's examine the receipt analyzer template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/receipt.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Receipt Analyzer**\n",
    "\n",
    "Now, let's create the receipt analyzer and process our sample receipt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/receipt.png'\n",
    "receipt_analyzer_id = \"receipt-extraction-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating receipt analyzer: {receipt_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(receipt_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Receipt analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing receipt: {sample_file_path}\")\n",
    "response = client.begin_analyze(receipt_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Receipt Analysis Results**\n",
    "\n",
    "Let's examine the extracted fields from the receipt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Receipt Analyzer**\n",
    "\n",
    "Optionally, clean up the receipt analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(receipt_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Analysis\n",
    "\n",
    "Next, let's move to audio analysis. This modality allows us to extract insights from audio files such as call recordings, including summaries, sentiment analysis, topic identification, and entity extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Call Recording Analytics\n",
    "\n",
    "Let's analyze a call center recording to extract insights such as summary, topics discussed, companies mentioned, and people involved in the conversation.\n",
    "\n",
    "**Call Recording Analytics Template**\n",
    "\n",
    "Let's examine the call recording analytics template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/call_recording_analytics.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Call Recording Analyzer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/callCenterRecording.mp3'\n",
    "call_analyzer_id = \"call-recording-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating call recording analyzer: {call_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(call_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Call recording analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing call recording: {sample_file_path}\")\n",
    "print(\"⏳ Note: Audio analysis may take longer than document analysis...\")\n",
    "response = client.begin_analyze(call_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Call Recording Analysis Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Call Recording Analyzer**\n",
    "\n",
    "Note: In production environments, analyzers are typically kept for reuse rather than deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(call_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conversational Audio Analytics\n",
    "\n",
    "Let's analyze the same audio file with a focus on conversational aspects like sentiment analysis and dialogue understanding.\n",
    "\n",
    "Conversational audio analytics template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/conversational_audio_analytics.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Conversational Audio Analyzer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/callCenterRecording.mp3'\n",
    "conversation_analyzer_id = \"conversational-audio-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating conversational audio analyzer: {conversation_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(conversation_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Conversational audio analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing conversational audio: {sample_file_path}\")\n",
    "print(\"⏳ Note: Audio analysis may take longer than document analysis...\")\n",
    "response = client.begin_analyze(conversation_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversational Audio Analysis Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Conversational Audio Analyzer**\n",
    "\n",
    "Note: In production environments, analyzers are typically kept for reuse rather than deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(conversation_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Analysis\n",
    "\n",
    "Now, let's explore video analysis capabilities. This modality can extract insights from video content including descriptions, sentiment analysis, and identification of key scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Marketing Video Analysis\n",
    "\n",
    "Let's analyze a marketing video to extract descriptions, sentiment, and key insights that could be valuable for content understanding and marketing analytics.\n",
    "\n",
    "Content Understanding offers three segmentation options to slice a video, enabling you to get output for entire videos or short clips. You can specify these by setting the `segmentationMode` property in your custom analyzer:\n",
    "- Whole-video – `\"segmentationMode\": \"noSegmentation\"`  \n",
    "  The service treats the entire video file as a single segment and extracts metadata across its full duration.  \n",
    "  Examples:\n",
    "    - Compliance checks looking for specific brand-safety issues anywhere in an ad\n",
    "    - Full-length descriptive summaries\n",
    "- Automatic segmentation – `\"segmentationMode\": \"auto\"`  \n",
    "  The service analyzes the timeline, automatically segmenting the video. It groups successive shots into coherent scenes, capped at one minute each.  \n",
    "  Examples:\n",
    "    - Creating storyboards from a show\n",
    "    - Inserting mid-roll ads at logical pauses\n",
    "- Custom segmentation – `\"segmentationMode\": \"custom\"`  \n",
    "  You describe the segmentation logic in natural language, and the model creates segments accordingly. Set `segmentationDefinition` with a string describing your desired segmentation. Custom segmentation allows segments of varying length from seconds to minutes.  \n",
    "  Example:\n",
    "    - Breaking a news broadcast into distinct stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1 Analyze Without Segmentation\n",
    "\n",
    "In this example, we analyze a marketing video without segmentation.\n",
    "- Please set `segmentationMode` to `noSegmentation` in the analyzer schema `config` to process the entire video as a single segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/marketing_video.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Marketing Video Analyzer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/FlightSimulator.mp4'\n",
    "video_analyzer_id = \"marketing-video-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating marketing video analyzer: {video_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(video_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Marketing video analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing marketing video: {sample_file_path}\")\n",
    "print(\"⏳ Note: Video analysis may take significantly longer than document analysis...\")\n",
    "response = client.begin_analyze(video_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marketing video analysis result:\n",
    "- The result is generated from the content of the entire video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Marketing Video Analyzer**\n",
    "\n",
    "Note: In production environments, analyzers are typically kept for reuse rather than deleting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(video_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2 Analyze With Automatic Segmentation\n",
    "\n",
    "In this example, we use automatic segmentation for marketing video analytics.\n",
    "- Please set `segmentationMode` to `auto` in the analyzer schema `config` to enable automatic segmentation.\n",
    "- The defined fields for segment analysis must be declared under `fieldSchema` → `Segments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/marketing_video_segmenation_auto.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Marketing Video Analyzer with Automatic Segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/FlightSimulator.mp4'\n",
    "video_analyzer_id = \"marketing-video-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating marketing video analyzer: {video_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(video_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Marketing video analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing marketing video: {sample_file_path}\")\n",
    "print(\"⏳ Note: Video analysis may take significantly longer than document analysis...\")\n",
    "response = client.begin_analyze(video_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marketing video analysis result:\n",
    "- The output includes automatically segmented clips with descriptions in the markdown content.\n",
    "- The analyzer generates the fields defined in the schema separately for each segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Marketing Video Analyzer**\n",
    "\n",
    "Note: In production environments, analyzers are typically kept for reuse rather than deleting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(video_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3 Analyze With Custom Segmentation\n",
    "\n",
    "In this example, we use custom segmentation for marketing video analytics.\n",
    "- Please set `segmentationMode` to `custom`.\n",
    "- Provide a `segmentationDefinition` string describing how you'd like the video to be segmented.\n",
    "- The defined fields for segment analysis must be declared under `fieldSchema` → `Segments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/marketing_video_segmenation_custom.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Marketing Video Analyzer with Custom Segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/FlightSimulator.mp4'\n",
    "video_analyzer_id = \"marketing-video-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating marketing video analyzer: {video_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(video_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Marketing video analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing marketing video: {sample_file_path}\")\n",
    "print(\"⏳ Note: Video analysis may take significantly longer than document analysis...\")\n",
    "response = client.begin_analyze(video_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marketing video analysis result:\n",
    "- The video is segmented according to your custom definition, with segment descriptions included in the markdown content.\n",
    "- The segmentation may differ from automatic segmentation results.\n",
    "- The analyzer generates the fields defined in the schema separately for each segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Marketing Video Analyzer**\n",
    "\n",
    "Note: In production environments, analyzers are typically kept for reuse rather than deleting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(video_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis\n",
    "\n",
    "Finally, let's explore image analysis capabilities. This modality can extract information from charts, diagrams, and other visual content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Chart and Image Analysis\n",
    "\n",
    "Let's analyze a chart image to extract data points, trends, and insights from visual data representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image chart analytics template\n",
    "analyzer_template_path = '../analyzer_templates/image_chart.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Chart Image Analyzer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/pieChart.jpg'\n",
    "chart_analyzer_id = \"chart-analysis-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating chart analyzer: {chart_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(chart_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Chart analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing chart: {sample_file_path}\")\n",
    "response = client.begin_analyze(chart_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chart Analysis Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Chart Image Analyzer**\n",
    "\n",
    "Note: In production environments, analyzers are typically kept for reuse rather than deleting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(chart_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "🎉 **Congratulations!** You have successfully explored all the major modalities of Azure AI Content Understanding:\n",
    "\n",
    "✅ **Document Analysis**: Extracted fields from invoices and receipts\n",
    "✅ **Audio Analysis**: Analyzed call recordings and conversational audio\n",
    "✅ **Video Analysis**: Processed marketing videos for insights\n",
    "✅ **Image Analysis**: Extracted information from charts and visual content\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Multi-modal capabilities**: Content Understanding processes documents, audio, video, and images\n",
    "- **Customizable templates**: Each analyzer template is designed for specific use cases but can be customized\n",
    "- **Automatic cleanup**: Each analyzer was cleaned up after use to manage resources\n",
    "- **Structured output**: All results are returned in a consistent JSON format for easy integration\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore the analyzer templates located in the `../analyzer_templates/` directory\n",
    "- Modify existing templates or create custom ones tailored to your specific use cases\n",
    "- Check out other notebooks in this repository for advanced scenarios\n",
    "- Visit the [Azure AI Content Understanding documentation](https://docs.microsoft.com/azure/ai-services/content-understanding/) for more information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}