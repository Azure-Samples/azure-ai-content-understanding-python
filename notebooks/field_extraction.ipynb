{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Custom Fields from Your File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use analyzers to extract custom fields from your input files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "1. Ensure Azure AI service is configured following [steps](../README.md#configure-azure-ai-service-resource)\n",
    "2. Install the required packages to run the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure AI Content Understanding Client\n",
    "\n",
    "> The [AzureContentUnderstandingClient](../python/content_understanding_client.py) is a utility class containing functions to interact with the Content Understanding API. Before the official release of the Content Understanding SDK, it can be regarded as a lightweight SDK. Fill the constant **AZURE_AI_ENDPOINT**, **AZURE_AI_API_VERSION**, **AZURE_AI_API_KEY** with the information from your Azure AI Service.\n",
    "\n",
    "> ⚠️ Important:\n",
    "You must update the code below to match your Azure authentication method.\n",
    "Look for the `# IMPORTANT` comments and modify those sections accordingly.\n",
    "If you skip this step, the sample may not run correctly.\n",
    "\n",
    "> ⚠️ Note: Using a subscription key works, but using a token provider with Azure Active Directory (AAD) is much safer and is highly recommended for production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# For authentication, you can use either token-based auth or subscription key, and only one of them is required\n",
    "AZURE_AI_ENDPOINT = os.getenv(\"AZURE_AI_ENDPOINT\")\n",
    "# IMPORTANT: Replace with your actual subscription key or set up in \".env\" file if not using token auth\n",
    "AZURE_AI_API_KEY = os.getenv(\"AZURE_AI_API_KEY\")\n",
    "AZURE_AI_API_VERSION = os.getenv(\"AZURE_AI_API_VERSION\", \"2025-05-01-preview\")\n",
    "\n",
    "# Add the parent directory to the path to use shared modules\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "from python.content_understanding_client import AzureContentUnderstandingClient\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = AzureContentUnderstandingClient(\n",
    "    endpoint=AZURE_AI_ENDPOINT,\n",
    "    api_version=AZURE_AI_API_VERSION,\n",
    "    # IMPORTANT: Comment out token_provider if using subscription key\n",
    "    token_provider=token_provider,\n",
    "    # IMPORTANT: Uncomment this if using subscription key\n",
    "    # subscription_key=AZURE_AI_API_KEY,\n",
    "    x_ms_useragent=\"azure-ai-content-understanding-python/field_extraction\", # This header is used for sample usage telemetry, please comment out this line if you want to opt out.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates field extraction across multiple modalities using Azure AI Content Understanding. We'll walk through each modality step by step:\n",
    "\n",
    "1. **Document Analysis** - Extract fields from invoices and receipts\n",
    "2. **Audio Analysis** - Process call recordings and conversation audio  \n",
    "3. **Video Analysis** - Analyze marketing videos and extract insights\n",
    "4. **Image Analysis** - Extract information from charts and images\n",
    "\n",
    "Each section will create an analyzer, process sample data, display results, and clean up the analyzer before moving to the next modality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Analyzer Templates and Schemas\n",
    "\n",
    "Before we create our first analyzer, it's important to understand the structure and schema of analyzer templates. Custom analyzers in Azure AI Content Understanding are defined using JSON templates that specify what fields to extract and how to process the content.\n",
    "\n",
    "**Key Schema Components:**\n",
    "\n",
    "- **`baseAnalyzerId`**: This is crucial as it specifies which prebuilt analyzer to derive from (e.g., `prebuilt-documentAnalyzer`, `prebuilt-audioAnalyzer`, `prebuilt-videoAnalyzer`, `prebuilt-imageAnalyzer`, `prebuilt-callCenter`). This provides the foundation capabilities for your custom analyzer.\n",
    "\n",
    "- **`fields`**: Define the specific data points you want to extract. Each field has:\n",
    "  - **Field name**: The identifier for the extracted data (required and important for referencing results)\n",
    "  - **Description**: Optional but helpful for documentation and understanding the field's purpose\n",
    "  - **Method**: Can be `\"extract\"` (for extracting existing information from documents - currently only available for document analysis) or `\"generate\"` (for generating new insights using AI)\n",
    "\n",
    "- **`method`**: The overall extraction approach - use `\"extract\"` for standard field extraction from documents or `\"generate\"` when you need AI to generate insights or summaries.\n",
    "\n",
    "**Important Note**: The `\"extract\"` method is currently only available for document analysis (using `prebuilt-documentAnalyzer`). For other modalities like audio, video, and images, use the `\"generate\"` method.\n",
    "\n",
    "Let's examine the invoice template to see these concepts in action:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the schema for document modality used to extract fields from an invoice PDF. This analyzer identifies key invoice elements such as vendor information, amounts, dates, and line items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "analyzer_template_path = '../analyzer_templates/invoice.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example schema for the video modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/marketing_video.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Analysis\n",
    "\n",
    "Let's start with document analysis by extracting fields from invoices and receipts. This modality is excellent for processing structured documents and extracting key information like amounts, dates, vendor details, and line items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Invoice Field Extraction\n",
    "\n",
    "Let's extract fields from an invoice PDF. This analyzer identifies essential invoice elements such as vendor information, amounts, dates, and line items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/invoice.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Invoice Analyzer**\n",
    "\n",
    "Now let's create the invoice analyzer and process our sample invoice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/invoice.pdf'\n",
    "invoice_analyzer_id = \"invoice-extraction-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating invoice analyzer: {invoice_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(invoice_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Invoice analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing invoice: {sample_file_path}\")\n",
    "response = client.begin_analyze(invoice_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invoice Analysis Results**\n",
    "\n",
    "Let's examine the extracted fields from the invoice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Invoice Analyzer**\n",
    "\n",
    "Clean up the analyzer to manage resources (in production, you would typically keep analyzers for reuse):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(invoice_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Invoice Field Extraction with Source Grounding\n",
    "\n",
    "Now let's analyze the same invoice but with enhanced field source information and confidence scores. This provides additional context about where each extracted field was found in the document.\n",
    "\n",
    "**Note**: This custom analyzer is for demo purposes only. In production, users should start from `prebuilt-invoice` for invoice processing.\n",
    "\n",
    "**Key Feature**: This analyzer template uses `estimateFieldSourceAndConfidence: true` in the 'config', which enables the service to provide detailed information about:\n",
    "- **Field source locations**: Exact coordinates and bounding boxes where each field was found\n",
    "- **Confidence scores**: How confident the service is about each extracted field\n",
    "- **Enhanced metadata**: Additional context about the extraction process\n",
    "\n",
    "This is particularly useful for applications that need to verify extraction accuracy or provide visual feedback about where information was found in the source document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/invoice_field_source.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Invoice Field Source Analyzer**\n",
    "\n",
    "Now let's create the enhanced analyzer and process the invoice with source grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/invoice.pdf'\n",
    "invoice_source_analyzer_id = \"invoice-field-source-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating invoice field source analyzer: {invoice_source_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(invoice_source_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Invoice field source analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing invoice with field source: {sample_file_path}\")\n",
    "response = client.begin_analyze(invoice_source_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invoice Field Source Analysis Results**\n",
    "\n",
    "Let's review the enhanced results, which include detailed field source locations and confidence scores. Pay special attention to the `confidence` and `source` attributes for each extracted field. The `source` attribute provides the page number and bounding box coordinates for the extracted data, offering precise context for verification and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Invoice Field Source Analyzer**\n",
    "\n",
    "Clean up the field source analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(invoice_source_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Receipt Field Extraction\n",
    "\n",
    "Let's extract information from a receipt image. This demonstrates how the same Content Understanding service can handle different document types and formats.\n",
    "\n",
    "**Receipt Analyzer Template**\n",
    "\n",
    "Let's examine the receipt analyzer template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/receipt.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and Run Receipt Analyzer**\n",
    "\n",
    "Now let's create the receipt analyzer and process our sample receipt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/receipt.png'\n",
    "receipt_analyzer_id = \"receipt-extraction-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating receipt analyzer: {receipt_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(receipt_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Receipt analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing receipt: {sample_file_path}\")\n",
    "response = client.begin_analyze(receipt_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Receipt Analysis Results**\n",
    "\n",
    "Let's examine the extracted fields from the receipt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Up Receipt Analyzer**\n",
    "\n",
    "Clean up the receipt analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(receipt_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Analysis\n",
    "\n",
    "Now let's move to audio analysis. This modality allows us to extract insights from audio files such as call recordings, including summaries, sentiment analysis, topic identification, and entity extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Call Recording Analytics\n",
    "\n",
    "Let's analyze a call center recording to extract insights such as summary, topics discussed, mentioned companies, and people involved in the conversation.\n",
    "\n",
    "**Call Recording Analytics Template**\n",
    "\n",
    "Let's examine the call recording analytics template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/call_recording_analytics.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run call recording analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/callCenterRecording.mp3'\n",
    "call_analyzer_id = \"call-recording-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating call recording analyzer: {call_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(call_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Call recording analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing call recording: {sample_file_path}\")\n",
    "print(\"⏳ Note: Audio analysis may take longer than document analysis...\")\n",
    "response = client.begin_analyze(call_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call recording analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up call recording analyzer\n",
    "\n",
    "Note: In production environments, you would typically keep analyzers for reuse rather than deleting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(call_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conversational Audio Analytics\n",
    "\n",
    "Let's analyze the same audio file but with a focus on conversational aspects like sentiment analysis and dialogue understanding.\n",
    "\n",
    "Conversational audio analytics template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/conversational_audio_analytics.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run conversational audio analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/callCenterRecording.mp3'\n",
    "conversation_analyzer_id = \"conversational-audio-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating conversational audio analyzer: {conversation_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(conversation_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Conversational audio analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing conversational audio: {sample_file_path}\")\n",
    "print(\"⏳ Note: Audio analysis may take longer than document analysis...\")\n",
    "response = client.begin_analyze(conversation_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversational audio analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up conversational audio analyzer\n",
    "\n",
    "Note: In production environments, you would typically keep analyzers for reuse rather than deleting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(conversation_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Analysis\n",
    "\n",
    "Now let's explore video analysis capabilities. This modality can extract insights from video content including descriptions, sentiment analysis, and key scene identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Marketing Video Analysis\n",
    "\n",
    "Let's analyze a marketing video to extract descriptions, sentiment, and key insights that could be valuable for content understanding and marketing analytics.\n",
    "\n",
    "Marketing video analytics template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template_path = '../analyzer_templates/marketing_video.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run marketing video analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/FlightSimulator.mp4'\n",
    "video_analyzer_id = \"marketing-video-analytics-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating marketing video analyzer: {video_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(video_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Marketing video analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing marketing video: {sample_file_path}\")\n",
    "print(\"⏳ Note: Video analysis may take significantly longer than document analysis...\")\n",
    "response = client.begin_analyze(video_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marketing video analysis result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up marketing video analyzer\n",
    "\n",
    "Note: In production environments, you would typically keep analyzers for reuse rather than deleting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(video_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis\n",
    "\n",
    "Finally, let's explore image analysis capabilities. This modality can extract information from charts, diagrams, and other visual content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Chart and Image Analysis\n",
    "\n",
    "Let's analyze a chart image to extract data points, trends, and insights from visual data representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image chart analytics template\n",
    "analyzer_template_path = '../analyzer_templates/image_chart.json'\n",
    "with open(analyzer_template_path, 'r') as f:\n",
    "    template_content = json.load(f)\n",
    "    print(json.dumps(template_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and run chart image analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = '../data/pieChart.jpg'\n",
    "chart_analyzer_id = \"chart-analysis-\" + str(uuid.uuid4())\n",
    "\n",
    "print(f\"Creating chart analyzer: {chart_analyzer_id}\")\n",
    "response = client.begin_create_analyzer(chart_analyzer_id, analyzer_template_path=analyzer_template_path)\n",
    "result = client.poll_result(response)\n",
    "print(\"✅ Chart analyzer created successfully!\")\n",
    "\n",
    "print(f\"Analyzing chart: {sample_file_path}\")\n",
    "response = client.begin_analyze(chart_analyzer_id, file_location=sample_file_path)\n",
    "result_json = client.poll_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chart analysis result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up chart image analyzer\n",
    "\n",
    "Note: In production environments, you would typically keep analyzers for reuse rather than deleting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(chart_analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "🎉 **Congratulations!** You've successfully explored all the major modalities of Azure AI Content Understanding:\n",
    "\n",
    "✅ **Document Analysis**: Extracted fields from invoices and receipts  \n",
    "✅ **Audio Analysis**: Analyzed call recordings and conversational audio  \n",
    "✅ **Video Analysis**: Processed marketing videos for insights  \n",
    "✅ **Image Analysis**: Extracted information from charts and visual content\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Multi-modal capabilities**: Content Understanding can process documents, audio, video, and images\n",
    "- **Customizable templates**: Each analyzer template is designed for specific use cases but can be customized\n",
    "- **Automatic cleanup**: Each analyzer was automatically cleaned up after use to manage resources\n",
    "- **Structured output**: All results are returned in consistent JSON format for easy integration\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore the analyzer templates in the `../analyzer_templates/` directory\n",
    "- Modify existing templates or create custom ones for your specific use cases\n",
    "- Check out other notebooks in this repository for advanced scenarios\n",
    "- Visit the [Azure AI Content Understanding documentation](https://docs.microsoft.com/azure/ai-services/content-understanding/) for more information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
