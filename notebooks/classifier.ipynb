{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Content Understanding - Classifier and Analyzer Demo\n",
    "\n",
    "This notebook demonstrates how to use the Azure AI Content Understanding service to:\n",
    "1. Create a classifier for document categorization\n",
    "2. Create a custom analyzer to extract specific fields\n",
    "3. Combine the classifier and analyzers to classify, optionally split, and analyze documents within a flexible processing pipeline\n",
    "\n",
    "For more detailed information before getting started, please refer to the official documentation:\n",
    "[Understanding Classifiers in Azure AI Services](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/concepts/classifier)\n",
    "\n",
    "## Prerequisites\n",
    "1. Ensure the Azure AI service is configured by following the [setup steps](../README.md#configure-azure-ai-service-resource).\n",
    "2. Install the required packages to run this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure AI Content Understanding Client\n",
    "\n",
    "> The [AzureContentUnderstandingClient](../python/content_understanding_client.py) is a utility class that provides functions to interact with the Content Understanding API. Prior to the official release of the Content Understanding SDK, it serves as a lightweight SDK.\n",
    ">\n",
    "> Fill in the constants **AZURE_AI_ENDPOINT**, **AZURE_AI_API_VERSION**, and **AZURE_AI_API_KEY** with the details from your Azure AI Service.\n",
    "\n",
    "> ‚ö†Ô∏è Important:\n",
    "You must update the code below to use your preferred Azure authentication method.\n",
    "Look for the `# IMPORTANT` comments in the code and modify those sections accordingly.\n",
    "Skipping this step may cause the sample to not run correctly.\n",
    "\n",
    "> ‚ö†Ô∏è Note: While using a subscription key is supported, it is strongly recommended to use a token provider with Azure Active Directory (AAD) for enhanced security in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv azure-ai-contentunderstanding azure-identity\n",
    "\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.ai.contentunderstanding.aio import ContentUnderstandingClient\n",
    "from azure.ai.contentunderstanding.models import (\n",
    "    ContentClassifier,\n",
    "    ContentAnalyzer,\n",
    "    ClassifierCategory,\n",
    "    DocumentContent,\n",
    "    FieldSchema,\n",
    "    FieldDefinition,\n",
    "    FieldType,\n",
    "    ContentAnalyzerConfig,\n",
    ")\n",
    "\n",
    "# Add the parent directory to the Python path to import the sample_helper module\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'python'))\n",
    "from extension.sample_helper import extract_operation_id_from_poller, save_json_to_file, PollerType\n",
    "from typing import Dict, Optional\n",
    "\n",
    "load_dotenv()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "endpoint = os.environ.get(\"AZURE_CONTENT_UNDERSTANDING_ENDPOINT\")\n",
    "# Return AzureKeyCredential if AZURE_CONTENT_UNDERSTANDING_KEY is set, otherwise DefaultAzureCredential\n",
    "key = os.getenv(\"AZURE_CONTENT_UNDERSTANDING_KEY\")\n",
    "credential = AzureKeyCredential(key) if key else DefaultAzureCredential()\n",
    "# Create the ContentUnderstandingClient\n",
    "client = ContentUnderstandingClient(endpoint=endpoint, credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Basic Classifier\n",
    "Classify document from URL using begin_classify API.\n",
    "\n",
    "High-level steps:\n",
    "1. Create a custom classifier\n",
    "2. Classify a document from a remote URL\n",
    "3. Save the classification result to a file\n",
    "4. Clean up the created classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple ContentClassifier object with default configuration.\n",
    "\n",
    "# Args:\n",
    "#     classifier_id: The classifier ID\n",
    "#     description: Optional description for the classifier\n",
    "#     tags: Optional tags for the classifier\n",
    "\n",
    "# Returns:\n",
    "#     ContentClassifier: A configured ContentClassifier object\n",
    "\n",
    "def create_classifier_schema(description: Optional[str] = None, tags: Optional[Dict[str, str]] = None) -> ContentClassifier:\n",
    "    categories = {\n",
    "        \"Loan application\": ClassifierCategory(\n",
    "            description=\"Documents submitted by individuals or businesses to request funding, typically including personal or business details, financial history, loan amount, purpose, and supporting documentation.\"\n",
    "        ),\n",
    "        \"Invoice\": ClassifierCategory(\n",
    "            description=\"Billing documents issued by sellers or service providers to request payment for goods or services, detailing items, prices, taxes, totals, and payment terms.\"\n",
    "        ),\n",
    "        \"Bank_Statement\": ClassifierCategory(\n",
    "            description=\"Official statements issued by banks that summarize account activity over a period, including deposits, withdrawals, fees, and balances.\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    classifier = ContentClassifier(\n",
    "        categories=categories,\n",
    "        split_mode=\"auto\",\n",
    "        description=description,\n",
    "        tags=tags,\n",
    "    )\n",
    "\n",
    "    return classifier\n",
    "\n",
    "# Generate a unique classifier ID\n",
    "classifier_id = f\"classifier-sample-{datetime.now().strftime('%Y%m%d')}-{datetime.now().strftime('%H%M%S')}-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Create a custom classifier using object model\n",
    "print(f\"üîß Creating custom classifier '{classifier_id}'...\")\n",
    "\n",
    "classifier_schema: ContentClassifier = create_classifier_schema(\n",
    "    description=f\"Custom classifier for URL classification demo: {classifier_id}\",\n",
    "    tags={\"demo_type\": \"url_classification\"},\n",
    ")\n",
    "\n",
    "# Start the classifier creation operation\n",
    "poller = await client.content_classifiers.begin_create_or_replace(\n",
    "    classifier_id=classifier_id,\n",
    "    resource=classifier_schema,\n",
    ")\n",
    "\n",
    "# Wait for the classifier to be created\n",
    "print(f\"‚è≥ Waiting for classifier creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"‚úÖ Classifier '{classifier_id}' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Your Document\n",
    "\n",
    "Now, use the classifier to categorize your document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the mixed financial docs PDF file\n",
    "pdf_path = \"../data/mixed_financial_docs.pdf\"\n",
    "print(f\"üìÑ Reading document file: {pdf_path}\")\n",
    "with open(pdf_path, \"rb\") as pdf_file:\n",
    "    pdf_content = pdf_file.read()\n",
    "\n",
    "# Begin binary classification operation\n",
    "print(f\"üîç Starting binary classification with classifier '{classifier_id}'...\")\n",
    "classification_poller = await client.content_classifiers.begin_classify_binary(\n",
    "    classifier_id=classifier_id,\n",
    "    input=pdf_content,\n",
    "    content_type=\"application/pdf\",\n",
    ")\n",
    "\n",
    "# Wait for classification completion\n",
    "print(f\"‚è≥ Waiting for classification to complete...\")\n",
    "classification_result = await classification_poller.result()\n",
    "print(f\"‚úÖ Classification completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result\n",
    "classification_operation_id = extract_operation_id_from_poller(\n",
    "    classification_poller, PollerType.CLASSIFY_CALL\n",
    ")\n",
    "print(\n",
    "    f\"üìã Extracted classification operation ID: {classification_operation_id}\"\n",
    ")\n",
    "\n",
    "# Get the classification result using the operation ID\n",
    "print(\n",
    "    f\"üîç Getting classification result using operation ID '{classification_operation_id}'...\"\n",
    ")\n",
    "operation_status = await client.content_classifiers.get_result(\n",
    "    operation_id=classification_operation_id,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Classification result retrieved successfully!\")\n",
    "print(f\"   Operation ID: {getattr(operation_status, 'id', 'N/A')}\")\n",
    "print(f\"   Status: {getattr(operation_status, 'status', 'N/A')}\")\n",
    "\n",
    "# The actual classification result is in operation_status.result\n",
    "operation_result = getattr(operation_status, \"result\", None)\n",
    "if operation_result is not None:\n",
    "    print(\n",
    "        f\"   Result contains {len(getattr(operation_result, 'contents', []))} contents\"\n",
    "    )\n",
    "\n",
    "# Save the classification result to a file\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=operation_status.as_dict(),\n",
    "    filename_prefix=\"content_classifiers_get_result\",\n",
    ")\n",
    "print(f\"üíæ Classification result saved to: {saved_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Classification Results\n",
    "\n",
    "Review the classification results generated for your document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification results\n",
    "print(f\"üìä Classification Results:\")\n",
    "for content in classification_result.contents:\n",
    "    document_content: DocumentContent = content\n",
    "    print(f\"   Category: {document_content.category}\")\n",
    "    print(f\"       Start Page Number: {document_content.start_page_number}\")\n",
    "    print(f\"       End Page Number: {document_content.end_page_number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Classification Results\n",
    "The classification result is saved to a JSON file for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classification result to a file\n",
    "\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=classification_result.as_dict(),\n",
    "    filename_prefix=\"content_classifiers_classify\",\n",
    ")\n",
    "print(f\"üíæ Classification result saved to: {saved_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the created analyzer \n",
    "After the demo completes, the classifier is automatically deleted to prevent resource accumulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the created classifier (demo cleanup)\n",
    "print(f\"üóëÔ∏è  Deleting classifier '{classifier_id}' (demo cleanup)...\")\n",
    "await client.content_classifiers.delete(classifier_id=classifier_id)\n",
    "print(f\"‚úÖ Classifier '{classifier_id}' deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Custom Analyzer (Advanced)\n",
    "\n",
    "Create a custom analyzer to extract specific fields from documents.\n",
    "This example extracts common fields from loan application documents and generates document excerpts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Define fields schema\n",
    "custom_analyzer = ContentAnalyzer(\n",
    "    base_analyzer_id=\"prebuilt-documentAnalyzer\",  # Built on top of the general document analyzer\n",
    "    description=\"Loan application analyzer - extracts key information from loan applications\",\n",
    "    config=ContentAnalyzerConfig(\n",
    "        return_details=True,\n",
    "        enable_layout=True,          # Extract layout details\n",
    "        enable_formula=False,        # Disable formula detection\n",
    "        estimate_field_source_and_confidence=True, # Enable estimation of field location and confidence\n",
    "        disable_content_filtering=False\n",
    "    ),\n",
    "    field_schema=FieldSchema(\n",
    "        fields={\n",
    "            \"ApplicationDate\": FieldDefinition(\n",
    "                type=FieldType.DATE,\n",
    "                method=\"generate\",\n",
    "                description=\"The date when the loan application was submitted.\"\n",
    "            ),\n",
    "            \"ApplicantName\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=\"generate\",\n",
    "                description=\"Full name of the loan applicant or company.\"\n",
    "            ),\n",
    "            \"LoanAmountRequested\": FieldDefinition(\n",
    "                type=FieldType.NUMBER,\n",
    "                method=\"generate\",\n",
    "                description=\"The total loan amount requested by the applicant.\"\n",
    "            ),\n",
    "            \"LoanPurpose\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=\"generate\",\n",
    "                description=\"The stated purpose or reason for the loan.\"\n",
    "            ),\n",
    "            \"CreditScore\": FieldDefinition(\n",
    "                type=FieldType.NUMBER,\n",
    "                method=\"generate\",\n",
    "                description=\"Credit score of the applicant, if available.\"\n",
    "            ),\n",
    "            \"Summary\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                method=\"generate\",\n",
    "                description=\"A brief summary overview of the loan application details.\"\n",
    "            )\n",
    "        }\n",
    "    ),\n",
    "    tags={\"demo\": \"loan-application\"}\n",
    ")\n",
    "\n",
    "# Generate a unique analyzer ID\n",
    "analyzer_id = f\"classifier-sample-{datetime.now().strftime('%Y%m%d')}-{datetime.now().strftime('%H%M%S')}-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Create the custom analyzer\n",
    "print(f\"üîß Creating custom analyzer '{analyzer_id}'...\")\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=analyzer_id,\n",
    "    resource=custom_analyzer,\n",
    ")\n",
    "result = await poller.result()\n",
    "print(f\"‚úÖ Analyzer '{analyzer_id}' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Enhanced Classifier with Custom Analyzer\n",
    "\n",
    "Now create a new classifier that uses the prebuilt invoice analyzer for invoices and the custom analyzer for loan application documents.\n",
    "This combines document classification with field extraction in one operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_classifier_schema(analyzer_id: str, description: Optional[str] = None, tags: Optional[Dict[str, str]] = None) -> ContentClassifier:\n",
    "    categories = {\n",
    "        \"Loan application\": {  # Both spaces and underscores allowed\n",
    "            \"description\": \"Documents submitted by individuals or businesses requesting funding, including personal/business details, financial history, and supporting documents.\",\n",
    "            \"analyzerId\": analyzer_id  # IMPORTANT: Use the custom analyzer created previously for loan applications\n",
    "        },\n",
    "        \"Invoice\": {\n",
    "            \"description\": \"Billing documents issued by sellers or service providers requesting payment for goods or services, detailing items, prices, taxes, totals, and payment terms.\",\n",
    "            \"analyzerId\": \"prebuilt-invoice\"  # Use prebuilt invoice analyzer for invoices\n",
    "        },\n",
    "        \"Bank_Statement\": {  # Both spaces and underscores allowed\n",
    "            \"description\": \"Official bank statements summarizing account activity over a period, including deposits, withdrawals, fees, and balances.\"\n",
    "            # No analyzer specified - uses default processing\n",
    "        }\n",
    "    }\n",
    "\n",
    "    classifier = ContentClassifier(\n",
    "        categories=categories,\n",
    "        split_mode=\"auto\",\n",
    "        description=description,\n",
    "        tags=tags,\n",
    "    )\n",
    "\n",
    "    return classifier\n",
    "\n",
    "# Generate a unique enhanced classifier ID\n",
    "classifier_id = f\"enhanced-classifier-sample-{datetime.now().strftime('%Y%m%d')}-{datetime.now().strftime('%H%M%S')}-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Create the enhanced classifier schema\n",
    "enhanced_classifier_schema = create_enhanced_classifier_schema(\n",
    "    analyzer_id=analyzer_id,\n",
    "    description=f\"Custom classifier for URL classification demo: {classifier_id}\",\n",
    "    tags={\"demo_type\": \"url_classification\"}\n",
    ")\n",
    "\n",
    "# Create the enhanced classifier only if the custom analyzer was created successfully\n",
    "if analyzer_id:\n",
    "    poller = await client.content_classifiers.begin_create_or_replace(\n",
    "        classifier_id=classifier_id,\n",
    "        resource=enhanced_classifier_schema\n",
    "    )\n",
    "\n",
    "    # Wait for the classifier to be created\n",
    "    print(f\"‚è≥ Waiting for classifier creation to complete...\")\n",
    "    await poller.result()\n",
    "    print(f\"‚úÖ Classifier '{classifier_id}' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Document with Enhanced Classifier\n",
    "\n",
    "Process the document again using the enhanced classifier.\n",
    "Invoices and loan applications will now have additional fields extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classifier_id and analyzer_id:\n",
    "    pdf_path = \"../data/mixed_financial_docs.pdf\"\n",
    "    print(f\"üìÑ Reading document file: {pdf_path}\")\n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        pdf_content = pdf_file.read()\n",
    "\n",
    "    # Begin binary classification operation\n",
    "    print(f\"üîç Starting binary classification with classifier '{classifier_id}'...\")\n",
    "    classification_poller = await client.content_classifiers.begin_classify_binary(\n",
    "        classifier_id=classifier_id,\n",
    "        input=pdf_content,\n",
    "        content_type=\"application/pdf\",\n",
    "    )\n",
    "\n",
    "    # Wait for classification completion\n",
    "    print(f\"‚è≥ Waiting for classification to complete...\")\n",
    "    classification_result = await classification_poller.result()\n",
    "    print(f\"‚úÖ Classification completed successfully!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping enhanced classification - enhanced classifier was not created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Enhanced Results with Extracted Fields\n",
    "\n",
    "Review the classification results alongside extracted fields from loan application documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification results\n",
    "print(f\"üìä Classification Results: {json.dumps(classification_result.as_dict(), indent=2)}\")\n",
    "for content in classification_result.contents:\n",
    "    if hasattr(content, \"classifications\") and content.classifications:\n",
    "        for classification in content.classifications:\n",
    "            print(f\"   Category: {classification.category}\")\n",
    "            print(f\"   Confidence: {classification.confidence}\")\n",
    "            print(f\"   Score: {classification.score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Classification Results\n",
    "The classification result is saved to a JSON file for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classification result to a file\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=classification_result.as_dict(),\n",
    "    filename_prefix=\"content_classifiers_classify_binary\",\n",
    ")\n",
    "print(f\"üíæ Classification result saved to: {saved_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the created analyzer\n",
    "After the demo completes, the analyzer is automatically deleted to prevent resource accumulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the created analyzer (demo cleanup)\n",
    "print(f\"üóëÔ∏è  Deleting analyzer '{analyzer_id}' (demo cleanup)...\")\n",
    "await client.content_analyzers.delete(analyzer_id=analyzer_id)\n",
    "print(f\"‚úÖ Analyzer '{analyzer_id}' deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the created classifier\n",
    "After the demo completes, the classifier is automatically deleted to prevent resource accumulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the created classifier (demo cleanup)\n",
    "print(f\"üóëÔ∏è  Deleting classifier '{classifier_id}' (demo cleanup)...\")\n",
    "await client.content_classifiers.delete(classifier_id=classifier_id)\n",
    "print(f\"‚úÖ Classifier '{classifier_id}' deleted successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
