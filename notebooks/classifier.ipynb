{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Content Understanding - Classifier and Analyzer Demo\n",
    "\n",
    "This notebook demonstrates how to use the Azure AI Content Understanding service to:\n",
    "1. Create a classifier for document categorization\n",
    "2. Create a custom analyzer to extract specific fields\n",
    "3. Combine the classifier and analyzers to classify, optionally split, and analyze documents within a flexible processing pipeline\n",
    "\n",
    "For more detailed information before getting started, please refer to the official documentation:\n",
    "[Understanding Classifiers in Azure AI Services](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/concepts/classifier)\n",
    "\n",
    "## Prerequisites\n",
    "1. Ensure the Azure AI service is configured by following the [setup steps](../README.md#configure-azure-ai-service-resource).\n",
    "2. Install the required packages to run this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Azure Content Understanding Client\n",
    "\n",
    "The `AzureContentUnderstandingClient` class manages all API interactions with the Azure AI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to the system path to access shared modules\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "try:\n",
    "    from python.content_understanding_client import AzureContentUnderstandingClient\n",
    "    print(\"‚úÖ Azure Content Understanding Client imported successfully!\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Error: Ensure 'AzureContentUnderstandingClient.py' exists in the same directory as this notebook.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Azure AI Service Settings and Prepare the Sample\n",
    "\n",
    "Update the following settings to match your Azure environment:\n",
    "\n",
    "- **AZURE_AI_ENDPOINT**: Your Azure AI service endpoint URL, or configure it in the \".env\" file\n",
    "- **AZURE_AI_API_VERSION**: Azure AI API version to use. Defaults to \"2025-05-01-preview\"\n",
    "- **AZURE_AI_API_KEY**: Your Azure AI API key (optional if using token-based authentication)\n",
    "- **ANALYZER_SAMPLE_FILE**: Path to the PDF document you want to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication supports either token-based or subscription key methods; only one is required\n",
    "AZURE_AI_ENDPOINT = os.getenv(\"AZURE_AI_ENDPOINT\")\n",
    "# IMPORTANT: Substitute with your subscription key or configure in \".env\" if not using token auth\n",
    "AZURE_AI_API_KEY = os.getenv(\"AZURE_AI_API_KEY\")\n",
    "AZURE_AI_API_VERSION = os.getenv(\"AZURE_AI_API_VERSION\", \"2025-05-01-preview\")\n",
    "ANALYZER_SAMPLE_FILE = \"../data/mixed_financial_docs.pdf\"  # Update this path to your PDF file\n",
    "\n",
    "# Use DefaultAzureCredential for token-based authentication\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "file_location = Path(ANALYZER_SAMPLE_FILE)\n",
    "\n",
    "print(\"üìã Configuration Summary:\")\n",
    "print(f\"   Endpoint: {AZURE_AI_ENDPOINT}\")\n",
    "print(f\"   API Version: {AZURE_AI_API_VERSION}\")\n",
    "print(f\"   Document: {file_location.name if file_location.exists() else '‚ùå File not found'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Classifier Schema\n",
    "\n",
    "The classifier schema defines:\n",
    "- **Categories**: Document types to classify (e.g., Legal, Medical)\n",
    "  - **description (Optional)**: Provides additional context or hints for categorizing or splitting documents. Useful when the category name alone is not sufficiently descriptive. Omit if the category name is self-explanatory.\n",
    "- **splitMode Options**: Determines how multi-page documents are split before classification or analysis.\n",
    "  - `\"auto\"`: Automatically split based on content.  \n",
    "    For example, given categories ‚Äúinvoice‚Äù and ‚Äúapplication form‚Äù:\n",
    "      - A PDF with one invoice will be classified as a single document.\n",
    "      - A PDF containing two invoices and one application form will be automatically split into three classified sections.\n",
    "  - `\"none\"`: No splitting.  \n",
    "    The entire multi-page document is treated as one unit for classification and analysis.\n",
    "  - `\"perPage\"`: Split by page.  \n",
    "    Treats each page as a separate document, useful if custom analyzers designed to operate at the page level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define document categories and their descriptions\n",
    "classifier_schema = {\n",
    "    \"categories\": {\n",
    "        \"Loan application\": {  # Both spaces and underscores are supported in category names\n",
    "            \"description\": \"Documents submitted by individuals or businesses to request funding, typically including personal or business details, financial history, loan amount, purpose, and supporting documentation.\"\n",
    "        },\n",
    "        \"Invoice\": {\n",
    "            \"description\": \"Billing documents issued by sellers or service providers to request payment for goods or services, detailing items, prices, taxes, totals, and payment terms.\"\n",
    "        },\n",
    "        \"Bank_Statement\": {  # Both spaces and underscores are supported\n",
    "            \"description\": \"Official statements issued by banks summarizing account activity over a period, including deposits, withdrawals, fees, and balances.\"\n",
    "        },\n",
    "    },\n",
    "    \"splitMode\": \"auto\"  # IMPORTANT: Automatically detect document boundaries; adjust as needed.\n",
    "}\n",
    "\n",
    "print(\"üìÑ Classifier Categories:\")\n",
    "for category, details in classifier_schema[\"categories\"].items():\n",
    "    print(f\"   ‚Ä¢ {category}: {details['description'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Content Understanding Client\n",
    "\n",
    "Create the client to interact with Azure AI services.\n",
    "\n",
    "‚ö†Ô∏è Important:\n",
    "Please update the authentication details below to match your Azure setup.\n",
    "Look for the `# IMPORTANT` comments and modify those sections accordingly.\n",
    "Skipping this step may result in runtime errors.\n",
    "\n",
    "‚ö†Ô∏è Note: While subscription key authentication works, using Azure Active Directory (AAD) token provider is more secure and recommended for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Azure Content Understanding client\n",
    "try:\n",
    "    content_understanding_client = AzureContentUnderstandingClient(\n",
    "        endpoint=AZURE_AI_ENDPOINT,\n",
    "        api_version=AZURE_AI_API_VERSION,\n",
    "        # IMPORTANT: Comment out token_provider if using subscription key\n",
    "        token_provider=token_provider,\n",
    "        # IMPORTANT: Uncomment this if using subscription key\n",
    "        # subscription_key=AZURE_AI_API_KEY,\n",
    "    )\n",
    "    print(\"‚úÖ Content Understanding client initialized successfully!\")\n",
    "    print(\"   Ready to create classifiers and analyzers.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize client: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create a Basic Classifier\n",
    "\n",
    "First, create a simple classifier that categorizes documents without performing additional analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique classifier ID\n",
    "classifier_id = \"classifier-sample-\" + str(uuid.uuid4())\n",
    "\n",
    "try:\n",
    "    # Create the classifier\n",
    "    print(f\"üî® Creating classifier: {classifier_id}\")\n",
    "    print(\"   This may take a few seconds...\")\n",
    "    \n",
    "    response = content_understanding_client.begin_create_classifier(classifier_id, classifier_schema)\n",
    "    result = content_understanding_client.poll_result(response)\n",
    "    \n",
    "    print(\"\\n‚úÖ Classifier created successfully!\")\n",
    "    print(f\"   Status: {result.get('status')}\")\n",
    "    print(f\"   Resource Location: {result.get('resourceLocation')}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creating classifier: {e}\")\n",
    "    if \"already exists\" in str(e):\n",
    "        print(\"\\nüí° Tip: The classifier already exists. You can:\")\n",
    "        print(\"   1. Use a different classifier ID\")\n",
    "        print(\"   2. Delete the existing classifier first\")\n",
    "        print(\"   3. Skip to document classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Classify Your Document\n",
    "\n",
    "Now, use the classifier to categorize your document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Verify that the document exists\n",
    "    if not file_location.exists():\n",
    "        raise FileNotFoundError(f\"Document not found at {file_location}\")\n",
    "    \n",
    "    # Classify the document\n",
    "    print(f\"üìÑ Classifying document: {file_location.name}\")\n",
    "    print(\"\\n‚è≥ Processing... This may take several minutes for large documents.\")\n",
    "    \n",
    "    response = content_understanding_client.begin_classify(classifier_id, file_location=str(file_location))\n",
    "    result = content_understanding_client.poll_result(response, timeout_seconds=360)\n",
    "    \n",
    "    print(\"\\n‚úÖ Classification completed successfully!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n‚ùå Document not found: {file_location}\")\n",
    "    print(\"   Please update 'file_location' to point to your PDF file.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error classifying document: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. View Classification Results\n",
    "\n",
    "Review the classification results generated for your document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification results\n",
    "if 'result' in locals() and result:\n",
    "    result_data = result.get(\"result\", {})\n",
    "    contents = result_data.get(\"contents\", [])\n",
    "    \n",
    "    print(\"üìä CLASSIFICATION RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"\\nTotal sections found: {len(contents)}\")\n",
    "    \n",
    "    # Summarize each classified section\n",
    "    print(\"\\nüìã Document Sections:\")\n",
    "    for i, content in enumerate(contents, 1):\n",
    "        print(f\"\\n   Section {i}:\")\n",
    "        print(f\"   ‚Ä¢ Category: {content.get('category', 'Unknown')}\")\n",
    "        print(f\"   ‚Ä¢ Pages: {content.get('startPageNumber', '?')} - {content.get('endPageNumber', '?')}\")\n",
    "        \n",
    "    print(\"\\nFull result output:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "else:\n",
    "    print(\"‚ùå No results available. Please run the classification step first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create a Custom Analyzer (Advanced)\n",
    "\n",
    "Create a custom analyzer to extract specific fields from documents.\n",
    "This example extracts common fields from loan application documents and generates document excerpts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the analyzer schema with custom fields\n",
    "analyzer_schema = {\n",
    "    \"description\": \"Loan application analyzer - extracts key information from loan applications\",\n",
    "    \"baseAnalyzerId\": \"prebuilt-documentAnalyzer\",  # Built on top of the general document analyzer\n",
    "    \"config\": {\n",
    "        \"returnDetails\": True,\n",
    "        \"enableLayout\": True,          # Extract layout details\n",
    "        \"enableBarcode\": False,        # Disable barcode detection\n",
    "        \"enableFormula\": False,        # Disable formula detection\n",
    "        \"estimateFieldSourceAndConfidence\": True, # Enable estimation of field location and confidence\n",
    "        \"disableContentFiltering\": False\n",
    "    },\n",
    "    \"fieldSchema\": {\n",
    "        \"fields\": {\n",
    "            \"ApplicationDate\": {\n",
    "                \"type\": \"date\",\n",
    "                \"method\": \"generate\",\n",
    "                \"description\": \"The date when the loan application was submitted.\"\n",
    "            },\n",
    "            \"ApplicantName\": {\n",
    "                \"type\": \"string\",\n",
    "                \"method\": \"generate\",\n",
    "                \"description\": \"Full name of the loan applicant or company.\"\n",
    "            },\n",
    "            \"LoanAmountRequested\": {\n",
    "                \"type\": \"number\",\n",
    "                \"method\": \"generate\",\n",
    "                \"description\": \"The total loan amount requested by the applicant.\"\n",
    "            },\n",
    "            \"LoanPurpose\": {\n",
    "                \"type\": \"string\",\n",
    "                \"method\": \"generate\",\n",
    "                \"description\": \"The stated purpose or reason for the loan.\"\n",
    "            },\n",
    "            \"CreditScore\": {\n",
    "                \"type\": \"number\",\n",
    "                \"method\": \"generate\",\n",
    "                \"description\": \"Credit score of the applicant, if available.\"\n",
    "            },\n",
    "            \"Summary\": {\n",
    "                \"type\": \"string\",\n",
    "                \"method\": \"generate\",\n",
    "                \"description\": \"A brief summary overview of the loan application details.\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate a unique analyzer ID\n",
    "analyzer_id = \"analyzer-loan-application-\" + str(uuid.uuid4())\n",
    "\n",
    "# Create the custom analyzer\n",
    "try:\n",
    "    print(f\"üî® Creating custom analyzer: {analyzer_id}\")\n",
    "    print(\"\\nüìã The analyzer will extract the following fields:\")\n",
    "    for field_name, field_info in analyzer_schema[\"fieldSchema\"][\"fields\"].items():\n",
    "        print(f\"   ‚Ä¢ {field_name}: {field_info['description']}\")\n",
    "    \n",
    "    response = content_understanding_client.begin_create_analyzer(analyzer_id, analyzer_schema)\n",
    "    result = content_understanding_client.poll_result(response)\n",
    "    \n",
    "    print(\"\\n‚úÖ Analyzer created successfully!\")\n",
    "    print(f\"   Analyzer ID: {analyzer_id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creating analyzer: {e}\")\n",
    "    analyzer_id = None  # Set to None if creation failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create an Enhanced Classifier with Custom Analyzer\n",
    "\n",
    "Now create a new classifier that uses the prebuilt invoice analyzer for invoices and the custom analyzer for loan application documents.\n",
    "This combines document classification with field extraction in one operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique enhanced classifier ID\n",
    "enhanced_classifier_id = \"classifier-enhanced-\" + str(uuid.uuid4())\n",
    "\n",
    "# Define the enhanced classifier schema\n",
    "enhanced_classifier_schema = {\n",
    "    \"categories\": {\n",
    "        \"Loan application\": {  # Both spaces and underscores allowed\n",
    "            \"description\": \"Documents submitted by individuals or businesses requesting funding, including personal/business details, financial history, and supporting documents.\",\n",
    "            \"analyzerId\": analyzer_id  # IMPORTANT: Use the custom analyzer created previously for loan applications\n",
    "        },\n",
    "        \"Invoice\": {\n",
    "            \"description\": \"Billing documents issued by sellers or service providers requesting payment for goods or services, detailing items, prices, taxes, totals, and payment terms.\",\n",
    "            \"analyzerId\": \"prebuilt-invoice\"  # Use prebuilt invoice analyzer for invoices\n",
    "        },\n",
    "        \"Bank_Statement\": {  # Both spaces and underscores allowed\n",
    "            \"description\": \"Official bank statements summarizing account activity over a period, including deposits, withdrawals, fees, and balances.\"\n",
    "            # No analyzer specified - uses default processing\n",
    "        }\n",
    "    },\n",
    "    \"splitMode\": \"auto\"\n",
    "}\n",
    "\n",
    "# Create the enhanced classifier only if the custom analyzer was created successfully\n",
    "if analyzer_id:\n",
    "    try:\n",
    "        print(f\"üî® Creating enhanced classifier: {enhanced_classifier_id}\")\n",
    "        print(\"\\nüìã Configuration:\")\n",
    "        print(\"   ‚Ä¢ Loan application documents ‚Üí Custom analyzer with field extraction\")\n",
    "        print(\"   ‚Ä¢ Invoice documents ‚Üí Prebuilt invoice analyzer\")\n",
    "        print(\"   ‚Ä¢ Bank_Statement documents ‚Üí Standard processing\")\n",
    "        \n",
    "        response = content_understanding_client.begin_create_classifier(enhanced_classifier_id, enhanced_classifier_schema)\n",
    "        result = content_understanding_client.poll_result(response)\n",
    "        \n",
    "        print(\"\\n‚úÖ Enhanced classifier created successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error creating enhanced classifier: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping enhanced classifier creation - custom analyzer was not created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Process Document with Enhanced Classifier\n",
    "\n",
    "Process the document again using the enhanced classifier.\n",
    "Invoices and loan applications will now have additional fields extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'enhanced_classifier_id' in locals() and analyzer_id:\n",
    "    try:\n",
    "        # Verify the document exists\n",
    "        if not file_location.exists():\n",
    "            raise FileNotFoundError(f\"Document not found at {file_location}\")\n",
    "        \n",
    "        # Process document with enhanced classifier\n",
    "        print(\"üìÑ Processing document with enhanced classifier\")\n",
    "        print(f\"   Document: {file_location.name}\")\n",
    "        print(\"\\n‚è≥ Processing with classification and field extraction...\")\n",
    "        \n",
    "        response = content_understanding_client.begin_classify(enhanced_classifier_id, file_location=str(file_location))\n",
    "        enhanced_result = content_understanding_client.poll_result(response, timeout_seconds=360)\n",
    "        \n",
    "        print(\"\\n‚úÖ Enhanced processing completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error processing document: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping enhanced classification - enhanced classifier was not created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. View Enhanced Results with Extracted Fields\n",
    "\n",
    "Review the classification results alongside extracted fields from loan application documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display enhanced classification results\n",
    "if 'enhanced_result' in locals() and enhanced_result:\n",
    "    result_data = enhanced_result.get(\"result\", {})\n",
    "    contents = result_data.get(\"contents\", [])\n",
    "    \n",
    "    print(\"üìä ENHANCED CLASSIFICATION RESULTS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nTotal sections found: {len(contents)}\")\n",
    "    \n",
    "    # Iterate through each document section\n",
    "    for i, content in enumerate(contents, 1):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"SECTION {i}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        category = content.get('category', 'Unknown')\n",
    "        print(f\"\\nüìÅ Category: {category}\")\n",
    "        print(f\"üìÑ Pages: {content.get('startPageNumber', '?')} - {content.get('endPageNumber', '?')}\")\n",
    "        \n",
    "        # Display extracted fields if available\n",
    "        fields = content.get('fields', {})\n",
    "        if fields:\n",
    "            print(\"\\nüîç Extracted Information:\")\n",
    "            for field_name, field_data in fields.items():\n",
    "                print(f\"\\n   {field_name}:\")\n",
    "                print(f\"   ‚Ä¢ Value: {field_data}\")\n",
    "else:\n",
    "    print(\"‚ùå No enhanced results available. Please run the enhanced classification step first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view the full JSON result below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(enhanced_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "Congratulations! You have successfully:\n",
    "1. ‚úÖ Created a basic classifier to categorize documents\n",
    "2. ‚úÖ Created a custom analyzer to extract specific fields\n",
    "3. ‚úÖ Combined them into an enhanced classifier for intelligent document processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
