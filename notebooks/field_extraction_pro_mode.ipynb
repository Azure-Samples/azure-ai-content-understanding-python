{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct Complex Analysis with Pro Mode\n",
    "\n",
    "> #################################################################################\n",
    ">\n",
    "> **Note:** Pro mode is currently available only for `document` data.  \n",
    "> [Supported file types](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/service-limits#document-and-text): pdf, tiff, jpg, jpeg, png, bmp, heif\n",
    ">\n",
    "> #################################################################################\n",
    "\n",
    "This notebook demonstrates how to use **Pro mode** in Azure AI Content Understanding to enhance your analyzer with multiple inputs and optional reference data. Pro mode is designed for advanced use cases, particularly those requiring multi-step reasoning and complex decision-making (for example, identifying inconsistencies, drawing inferences, and making sophisticated decisions). Pro mode allows input from multiple content files and includes the option to provide reference data at analyzer creation time.\n",
    "\n",
    "In this walkthrough, you'll learn how to:\n",
    "1. Create an analyzer with a schema and reference data.\n",
    "2. Analyze your files using Pro mode.\n",
    "\n",
    "For more details on Pro mode, see the [Azure AI Content Understanding: Standard and Pro Modes](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/concepts/standard-pro-modes) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "1. Ensure the Azure AI service is configured by following the [setup steps](../README.md#configure-azure-ai-service-resource).\n",
    "2. If using reference documents, please follow [Set env for reference doc](../docs/set_env_for_training_data_and_reference_doc.md) to configure reference document environment variables in the [.env](./.env) file.\n",
    "    - You can set `REFERENCE_DOC_SAS_URL` directly with the SAS URL for your Azure Blob container.\n",
    "    - Alternatively, set both `REFERENCE_DOC_STORAGE_ACCOUNT_NAME` and `REFERENCE_DOC_CONTAINER_NAME` so that the SAS URL can be generated automatically during a later step.\n",
    "    - Also, set `REFERENCE_DOC_PATH` to specify the folder path within the container where reference documents will be uploaded.\n",
    "    > âš ï¸ Note: Reference documents are optional in Pro mode. You can run Pro mode using only input documents. For example, the service can reason across two or more input files without any reference data.\n",
    "3. Install the required packages to run the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure Content Understanding Client\n",
    "> The [AzureContentUnderstandingClient](../python/content_understanding_client.py) is a utility class containing client functions. Before the official release of the Content Understanding SDK, consider it a lightweight SDK. Fill in the constants **AZURE_AI_ENDPOINT**, **AZURE_AI_API_VERSION**, and **AZURE_AI_API_KEY** with your Azure AI Service details.\n",
    "\n",
    "> âš ï¸ Important:\n",
    "You must update the code below to match your Azure authentication method.\n",
    "Look for the `# IMPORTANT` comments and modify those sections accordingly.\n",
    "If you skip this step, the sample may not run correctly.\n",
    "\n",
    "> âš ï¸ Note: Using a subscription key works, but using a token provider with Azure Active Directory (AAD) is recommended and safer for production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "from azure.storage.blob import ContainerSasPermissions\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.contentunderstanding.aio import ContentUnderstandingClient\n",
    "from azure.ai.contentunderstanding.models import (\n",
    "    AnalyzeResult,\n",
    "    AnalyzeInput,\n",
    "    ContentAnalyzer,\n",
    "    ContentAnalyzerConfig,\n",
    "    AnalysisMode,\n",
    "    ProcessingLocation,\n",
    "    AudioVisualContent,\n",
    "    FieldSchema,\n",
    "    FieldDefinition,\n",
    "    FieldType,\n",
    "    GenerationMethod,\n",
    ")\n",
    "from datetime import datetime\n",
    "from typing import Any\n",
    "import uuid\n",
    "\n",
    "# Add the parent directory to the Python path to import the sample_helper module\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'python'))\n",
    "from extension.document_processor import DocumentProcessor\n",
    "from extension.sample_helper import (\n",
    "    extract_operation_id_from_poller,\n",
    "    PollerType,\n",
    "    save_json_to_file,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "endpoint = os.environ.get(\"AZURE_CONTENT_UNDERSTANDING_ENDPOINT\")\n",
    "# Return AzureKeyCredential if AZURE_CONTENT_UNDERSTANDING_KEY is set, otherwise DefaultAzureCredential\n",
    "key = os.getenv(\"AZURE_CONTENT_UNDERSTANDING_KEY\")\n",
    "credential = AzureKeyCredential(key) if key else DefaultAzureCredential()\n",
    "# Create the ContentUnderstandingClient\n",
    "client = ContentUnderstandingClient(endpoint=endpoint, credential=credential)\n",
    "print(\"âœ… ContentUnderstandingClient created successfully\")\n",
    "\n",
    "try:\n",
    "    processor = DocumentProcessor(client)\n",
    "    print(\"âœ… DocumentProcessor created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to create DocumentProcessor: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Reference Data\n",
    "In this step, we will:\n",
    "- Use `REFERENCE_DOC_PATH` and SAS URL related environment variables that were set in the Prerequisites.\n",
    "- Attempt to obtain the SAS URL from the `REFERENCE_DOC_SAS_URL` environment variable.\n",
    "  If this is not set, the SAS URL will be generated automatically using the `REFERENCE_DOC_STORAGE_ACCOUNT_NAME` and `REFERENCE_DOC_CONTAINER_NAME` environment variables.\n",
    "- Use Azure AI service to extract OCR results from reference documents if needed.\n",
    "- Generate a reference `.jsonl` file.\n",
    "- Upload these files to the designated Azure Blob Storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference storage configuration from environment\n",
    "reference_doc_path = os.getenv(\"REFERENCE_DOC_PATH\") or f\"reference_docs_{uuid.uuid4().hex[:8]}\"\n",
    "reference_doc_sas_url = os.getenv(\"REFERENCE_DOC_SAS_URL\")\n",
    "\n",
    "if not reference_doc_path.endswith(\"/\"):\n",
    "    reference_doc_path += \"/\"\n",
    "\n",
    "if not reference_doc_sas_url:\n",
    "    reference_doc_storage_account_name = os.getenv(\"REFERENCE_DOC_STORAGE_ACCOUNT_NAME\")\n",
    "    reference_doc_container_name = os.getenv(\"REFERENCE_DOC_CONTAINER_NAME\")\n",
    "    print(f\"REFERENCE_DOC_STORAGE_ACCOUNT_NAME: {reference_doc_storage_account_name}\")\n",
    "    print(f\"REFERENCE_DOC_CONTAINER_NAME: {reference_doc_container_name}\")\n",
    "\n",
    "    if reference_doc_storage_account_name and reference_doc_container_name:\n",
    "        # We require \"Write\" permission to upload, modify, or append blobs\n",
    "        reference_doc_sas_url = processor.generate_container_sas_url(\n",
    "            account_name=reference_doc_storage_account_name,\n",
    "            container_name=reference_doc_container_name,\n",
    "            permissions=ContainerSasPermissions(read=True, write=True, list=True),\n",
    "            expiry_hours=1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> âš ï¸ Note: Reference documents are optional in Pro mode. You can run Pro mode using only input documents. For example, the service can reason across two or more input files without any reference data. To skip reference document preparation, please skip or comment out the code in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set skip_analyze to True if you already have OCR results for the documents in the reference_docs folder\n",
    "# Please name the OCR result files with the same name as the original document filenames including extension, and add the suffix \".result.json\"\n",
    "# For example, if the original document is \"invoice.pdf\", the OCR result file should be named \"invoice.pdf.result.json\"\n",
    "# NOTE: Please comment out the following line if you do not have any reference documents.\n",
    "reference_docs = \"../data/field_extraction_pro_mode/invoice_contract_verification/reference_docs\"\n",
    "print(f\"REFERENCE_DOCS: {reference_docs}\")\n",
    "print(f\"REFERENCE_DOC_SAS_URL: {reference_doc_sas_url}\")\n",
    "print(f\"REFERENCE_DOC_PATH: {reference_doc_path}\")\n",
    "await processor.generate_knowledge_base_on_blob(reference_docs, reference_doc_sas_url, reference_doc_path, skip_analyze=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Analyzer with Defined Schema for Pro Mode\n",
    "Before creating the analyzer, assign a relevant name to the constant **CUSTOM_ANALYZER_ID** for your task. Here, we generate a unique suffix so this cell can be run multiple times to create different analyzers.\n",
    "\n",
    "We use **reference_doc_sas_url** and **reference_doc_path** configured in the [.env](./.env) file and utilized in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_id = f\"pro-mode-sample-{datetime.now().strftime('%Y%m%d')}-{datetime.now().strftime('%H%M%S')}-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Create a custom analyzer using object model\n",
    "content_analyzer = ContentAnalyzer(\n",
    "    base_analyzer_id=\"prebuilt-documentAnalyzer\",\n",
    "    field_schema=FieldSchema(\n",
    "        name=\"InvoiceContractVerification\",\n",
    "        description=\"Analyze invoice to confirm total consistency with signed contract.\",\n",
    "        fields={\n",
    "            \"PaymentTermsInconsistencies\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"List all areas of inconsistency identified in the invoice with corresponding evidence.\",\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.OBJECT,\n",
    "                    method=GenerationMethod.GENERATE,\n",
    "                    description=\"Area of inconsistency in the invoice with the company's contracts.\",\n",
    "                    properties={\n",
    "                        \"Evidence\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.GENERATE,\n",
    "                            description=\"Evidence or reasoning for the inconsistency in the invoice.\"\n",
    "                        ),\n",
    "                        \"InvoiceField\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.GENERATE,\n",
    "                            description=\"Invoice field or the aspect that is inconsistent with the contract.\"\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            ),\n",
    "            \"ItemInconsistencies\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"List all areas of inconsistency identified in the invoice in the goods or services sold (including detailed specifications for every line item).\",\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.OBJECT,\n",
    "                    method=GenerationMethod.GENERATE,\n",
    "                    description=\"Area of inconsistency in the invoice with the company's contracts.\",\n",
    "                    properties={\n",
    "                        \"Evidence\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.GENERATE,\n",
    "                            description=\"Evidence or reasoning for the inconsistency in the invoice.\"\n",
    "                        ),\n",
    "                        \"InvoiceField\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.GENERATE,\n",
    "                            description=\"Invoice field or the aspect that is inconsistent with the contract.\"\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            ),\n",
    "            \"BillingLogisticsInconsistencies\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"List all areas of inconsistency identified in the invoice regarding billing logistics and administrative or legal issues.\",\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.OBJECT,\n",
    "                    method=GenerationMethod.GENERATE,\n",
    "                    description=\"Area of inconsistency in the invoice with the company's contracts.\",\n",
    "                    properties={\n",
    "                        \"Evidence\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.GENERATE,\n",
    "                            description=\"Evidence or reasoning for the inconsistency in the invoice.\"\n",
    "                        ),\n",
    "                        \"InvoiceField\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.GENERATE,\n",
    "                            description=\"Invoice field or the aspect that is inconsistent with the contract.\"\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            ),\n",
    "            \"PaymentScheduleInconsistencies\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"List all areas of inconsistency identified in the invoice with corresponding evidence.\",\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.OBJECT,\n",
    "                    method=GenerationMethod.GENERATE,\n",
    "                    description=\"Area of inconsistency in the invoice with the company's contracts.\",\n",
    "                    properties={\n",
    "                        \"Evidence\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.GENERATE,\n",
    "                            description=\"Evidence or reasoning for the inconsistency in the invoice.\"\n",
    "                        ),\n",
    "                        \"InvoiceField\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.GENERATE,\n",
    "                            description=\"Invoice field or the aspect that is inconsistent with the contract.\"\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            ),\n",
    "            \"TaxOrDiscountInconsistencies\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                method=GenerationMethod.GENERATE,\n",
    "                description=\"List all areas of inconsistency identified in the invoice with corresponding evidence regarding taxes or discounts.\",\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.OBJECT,\n",
    "                    method=GenerationMethod.GENERATE,\n",
    "                    description=\"Area of inconsistency in the invoice with the company's contracts.\",\n",
    "                    properties={\n",
    "                        \"Evidence\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.GENERATE,\n",
    "                            description=\"Evidence or reasoning for the inconsistency in the invoice.\"\n",
    "                        ),\n",
    "                        \"InvoiceField\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            method=GenerationMethod.GENERATE,\n",
    "                            description=\"Invoice field or the aspect that is inconsistent with the contract.\"\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    ),\n",
    "    mode=AnalysisMode.PRO,\n",
    "    processing_location=ProcessingLocation.GLOBAL,\n",
    "    knowledge_sources=[{\n",
    "        \"kind\": \"reference\",\n",
    "        \"containerUrl\": reference_doc_sas_url,\n",
    "        \"prefix\": reference_doc_path,\n",
    "        \"fileListPath\": processor.KNOWLEDGE_SOURCE_LIST_FILE_NAME,\n",
    "    }],\n",
    ")\n",
    "print(\"KNOWLEDGE_SOURCE_LIST_FILE_NAME\", processor.KNOWLEDGE_SOURCE_LIST_FILE_NAME)\n",
    "print(f\"ðŸ”§ Creating custom analyzer '{analyzer_id}'...\")\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=analyzer_id,\n",
    "    resource=content_analyzer,\n",
    ")\n",
    "\n",
    "# Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"ðŸ“‹ Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"â³ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"âœ… Analyzer '{analyzer_id}' created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Created Analyzer to Analyze Input Documents\n",
    "After the analyzer is successfully created, it can be used to analyze input files.\n",
    "> NOTE: Pro mode performs multi-step reasoning and may require more time for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_docs = \"../data/field_extraction_pro_mode/invoice_contract_verification/input_docs/contoso_lifts_invoice.pdf\"\n",
    "\n",
    "print(f\"ðŸ“„ Reading document file: {input_docs}\")\n",
    "with open(input_docs, \"rb\") as f:\n",
    "    pdf_content = f.read()\n",
    "\n",
    "print(f\"ðŸ” Starting document analysis with analyzer '{analyzer_id}'...\")\n",
    "analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=analyzer_id,\n",
    "    input=pdf_content,\n",
    "    content_type=\"application/pdf\"\n",
    ")\n",
    "\n",
    "# Wait for analysis completion\n",
    "print(f\"â³ Waiting for document analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(f\"âœ… Document analysis completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result\n",
    "analysis_operation_id = extract_operation_id_from_poller(\n",
    "    analysis_poller, PollerType.ANALYZE_CALL\n",
    ")\n",
    "print(f\"ðŸ“‹ Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "# Get the analysis result using the operation ID\n",
    "print(\n",
    "    f\"ðŸ” Getting analysis result using operation ID '{analysis_operation_id}'...\"\n",
    ")\n",
    "operation_status = await client.content_analyzers.get_result(\n",
    "    operation_id=analysis_operation_id,\n",
    ")\n",
    "\n",
    "# The actual analysis result is in operation_status.result\n",
    "operation_result = operation_status.result\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "saved_file_path = os.path.join(output_dir, f\"{analyzer_id}_result.json\")\n",
    "with open(saved_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(operation_result.as_dict(), file, indent=2)\n",
    "\n",
    "logging.info(f\"Full analyzer result saved to: {saved_file_path}\")\n",
    "print(f\"ðŸ’¾ Analysis result saved to: {saved_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's review the extracted fields with Pro mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(operation_result.as_dict(), indent=2))\n",
    "fields = operation_result.contents[0].fields\n",
    "print(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As seen in the `PaymentTermsInconsistencies` field, for example, the purchase contract details the payment terms agreed upon prior to the service. However, the implied payment terms on the invoice conflict with these. Pro mode identified the corresponding contract from the reference documents and analyzed it alongside the invoice to discover this inconsistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Existing Analyzer in Content Understanding Service\n",
    "This step is optional. It removes the test analyzer from your service to prevent it from persisting. Without deletion, the analyzer will remain for potential reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await client.content_analyzers.delete(analyzer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Sample\n",
    "This sample demonstrates how Pro mode supports multi-document input and advanced reasoning. Unlike Document Standard Mode, which processes one document at a time, Pro mode can analyze multiple documents within a single analysis call. The service not only processes each document independently but also cross-references documents to perform reasoning across them, enabling deeper insights and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, Set Up Variables for the Second Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for analyzer template, input documents, and reference documents of the second sample\n",
    "analyzer_template_2 = \"../analyzer_templates/insurance_claims_review_pro_mode.json\"\n",
    "input_docs_2 = \"../data/field_extraction_pro_mode/insurance_claims_review/input_docs\"\n",
    "reference_docs_2 = \"../data/field_extraction_pro_mode/insurance_claims_review/reference_docs2\"\n",
    "\n",
    "# Load reference storage configuration from environment\n",
    "reference_doc_path_2 = reference_doc_path.rstrip(\"/\") + \"_2/\"  # NOTE: Use a different path for the second sample\n",
    "analyzer_id_2 = \"pro-mode-sample-\" + str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Knowledge Base for the Second Sample\n",
    "Upload [reference documents](../data/field_extraction_pro_mode/insurance_claims_review/reference_docs/) with existing OCR results for the second sample. These documents contain driver coverage policies useful for reviewing insurance claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Start generating knowledge base for the second sample...\")\n",
    "# Reuse the same blob container\n",
    "await processor.generate_knowledge_base_on_blob(reference_docs_2, reference_doc_sas_url, reference_doc_path_2, skip_analyze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Analyzer for the Second Sample\n",
    "Reuse the existing AzureContentUnderstandingClient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_id = f\"pro-mode-sample-{datetime.now().strftime('%Y%m%d')}-{datetime.now().strftime('%H%M%S')}-{uuid.uuid4().hex[:8]}\"\n",
    "# Create a custom analyzer using object model\n",
    "print(f\"ðŸ”§ Creating custom analyzer '{analyzer_id}' for bonus...\")\n",
    "\n",
    "bonus_content_analyzer = ContentAnalyzer(\n",
    "    base_analyzer_id=\"prebuilt-documentAnalyzer\",\n",
    "    description=\"Bonus content analyzer for cleanup demonstration\",\n",
    "    field_schema=FieldSchema(\n",
    "        name=\"InsuranceClaimsReview\",\n",
    "        description=\"Analyze documents for insurance claim approval strictly according to the provided insurance policy. Consider all aspects of the insurance claim documents, any potential discrepancies found among the documents, any claims that should be flagged for review, etc.\",\n",
    "        fields={\n",
    "            \"CarBrand\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                description=\"Brand of the damaged vehicle.\",\n",
    "            ),\n",
    "            \"CarColor\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                description=\"Color of the damaged vehicle. Only use color name from 17 web colors. Use CamalCase naming convention.\",\n",
    "            ),\n",
    "            \"CarModel\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                description=\"Model of the damaged vehicle. Do not include brand name. Leave empty if not found.\",\n",
    "            ),\n",
    "            \"LicensePlate\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                description=\"License plate number of the damaged vehicle.\",\n",
    "            ),\n",
    "            \"VIN\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                description=\"VIN of the damaged vehicle. Leave empty if not found.\",\n",
    "            ),\n",
    "            \"ReportingOfficer\": FieldDefinition(\n",
    "                type=FieldType.STRING,\n",
    "                description=\"Name of the reporting officer for the incident.\",\n",
    "            ),\n",
    "            \"LineItemCorroboration\": FieldDefinition(\n",
    "                type=FieldType.ARRAY,\n",
    "                description=\"Validation of all of the line items on the claim, including parts, services, labors, materials, shipping and other costs and fees. When in doubt about adherence to the policy, mark as suspicious.\",\n",
    "                items_property=FieldDefinition(\n",
    "                    type=FieldType.OBJECT,\n",
    "                    description=\"Entry in the line item analysis table to analyze the pertinent information for the line item.\",\n",
    "                    properties={\n",
    "                        \"LineItemName\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            description=\"Name of the line item in the claim.\",\n",
    "                        ),\n",
    "                        \"IdentifiedVehiclePart\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            description=\"The relevant associated vehicle part for this line item\",\n",
    "                            enum=[\n",
    "                                \"BODY_TRIM\",\n",
    "                                \"DRIVER_SIDE_DRIVER_DOOR\",\n",
    "                                \"DRIVER_SIDE_DRIVER_HANDLE\",\n",
    "                                \"DRIVER_SIDE_FRONT_TIRE\",\n",
    "                                \"DRIVER_SIDE_FRONT_WHEEL\",\n",
    "                                \"DRIVER_SIDE_FUEL_CAP\",\n",
    "                                \"DRIVER_SIDE_PASSENGER_DOOR\",\n",
    "                                \"DRIVER_SIDE_PASSENGER_HANDLE\",\n",
    "                                \"DRIVER_SIDE_PASSENGER_WINDOW\",\n",
    "                                \"DRIVER_SIDE_REAR_HEADLAMP\",\n",
    "                                \"DRIVER_SIDE_REAR_TIRE\",\n",
    "                                \"DRIVER_SIDE_REAR_WHEEL\",\n",
    "                                \"DRIVER_SIDE_SIDE_WINDOW\",\n",
    "                                \"DRIVER_SIDE_WINDOW\",\n",
    "                                \"DRIVER_SIDE_WING_MIRROR\",\n",
    "                                \"FRONT_BONNET\",\n",
    "                                \"FRONT_BUMPER_LOWER\",\n",
    "                                \"FRONT_BUMPER_UPPER\",\n",
    "                                \"FRONT_DRIVER_SIDE_FOG_LIGHT\",\n",
    "                                \"FRONT_DRIVER_SIDE_HEADLAMP\",\n",
    "                                \"FRONT_GRILL\",\n",
    "                                \"FRONT_NUMBER_PLATE\",\n",
    "                                \"FRONT_PASSENGER_SIDE_FOG_LIGHT\",\n",
    "                                \"FRONT_PASSENGER_SIDE_HEADLAMP\",\n",
    "                                \"FRONT_WINDSHIELD\",\n",
    "                                \"PASSENGER_SIDE_DRIVER_DOOR\",\n",
    "                                \"PASSENGER_SIDE_DRIVER_HANDLE\",\n",
    "                                \"PASSENGER_SIDE_FRONT_TIRE\",\n",
    "                                \"PASSENGER_SIDE_FRONT_WHEEL\",\n",
    "                                \"PASSENGER_SIDE_PASSENGER_DOOR\",\n",
    "                                \"PASSENGER_SIDE_PASSENGER_HANDLE\",\n",
    "                                \"PASSENGER_SIDE_PASSENGER_WINDOW\",\n",
    "                                \"PASSENGER_SIDE_REAR_HEADLAMP\",\n",
    "                                \"PASSENGER_SIDE_REAR_TIRE\",\n",
    "                                \"PASSENGER_SIDE_REAR_WHEEL\",\n",
    "                                \"PASSENGER_SIDE_SIDE_WINDOW\",\n",
    "                                \"PASSENGER_SIDE_WINDOW\",\n",
    "                                \"PASSENGER_SIDE_WING_MIRROR\",\n",
    "                                \"REAR_BUMPER\",\n",
    "                                \"REAR_NUMBER_PLATE\",\n",
    "                                \"REAR_TRUNK\",\n",
    "                                \"REAR_WINDSHIELD\",\n",
    "                                \"ROOF_PANEL\",\n",
    "                                \"OTHER\"\n",
    "                            ]\n",
    "                        ),\n",
    "                        \"Cost\": FieldDefinition(\n",
    "                            type=FieldType.NUMBER,\n",
    "                            description=\"The cost of this line item on the claim.\",\n",
    "                        ),\n",
    "                        \"Evidence\": FieldDefinition(\n",
    "                            type=FieldType.ARRAY,\n",
    "                            description=\"The evidence for this line item entry, a list of the document with analyzed evidence supporting the claim formatted as <document name>/<evidence>. One of the insurance policy documents must be one of the documents.\",\n",
    "                            items_property=FieldDefinition(\n",
    "                                type=FieldType.STRING,\n",
    "                            )\n",
    "                        ),\n",
    "                        \"ClaimStatus\": FieldDefinition(\n",
    "                            type=FieldType.STRING,\n",
    "                            description=\"Determined by confidence in whether the claim should be approved based on the evidence. Item should be compliant to insurance policy and required for repairing the vehicle. Only use 'confirmed' for items explicitly approvable according to the policy. If unsure, use 'suspicious'.\",\n",
    "                            enum=[\n",
    "                                \"confirmed\",\n",
    "                                \"suspicious\",\n",
    "                                \"unconfirmed\"\n",
    "                            ],\n",
    "                            enum_descriptions={\n",
    "                                \"confirmed\": \"Completely and explicitly corroborated by the policy.\",\n",
    "                                \"suspicious\": \"Only partially verified, questionable, or otherwise uncertain evidence to approve automatically. Requires human review.\",\n",
    "                                \"unconfirmed\": \"Explicitly not approved by the policy.\"\n",
    "                            }\n",
    "                        )\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    ),\n",
    "    mode=AnalysisMode.PRO,\n",
    "    processing_location=ProcessingLocation.GLOBAL,\n",
    ")\n",
    "\n",
    "# Start the analyzer creation operation\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=analyzer_id,\n",
    "    resource=bonus_content_analyzer,\n",
    ")\n",
    "\n",
    "# Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"ðŸ“‹ Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"â³ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"âœ… Analyzer '{analyzer_id}' created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Multiple Input Documents with the Second Analyzer\n",
    "The [input_docs_2](../data/field_extraction_pro_mode/insurance_claims_review/input_docs/) folder contains two PDFs as input: a car accident report and a repair estimate.\n",
    "\n",
    "The first document includes details such as the carâ€™s license plate number, vehicle model, and incident information.\n",
    "The second document provides a breakdown of the estimated repair costs.\n",
    "\n",
    "Because of the complexity of this multi-document scenario, analysis may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_data: list[AnalyzeInput] = []\n",
    "input_dir = Path(input_docs_2)\n",
    "\n",
    "for file_path in input_dir.glob(\"*\"):\n",
    "    if file_path.is_file() and processor.is_supported_doc_type_by_file_path(file_path, is_document=True):\n",
    "        # Get relative path and replace separators with underscores\n",
    "        relative_path = file_path.relative_to(input_dir)\n",
    "        name = str(relative_path).replace(os.sep, '_').replace('/', '_').replace('\\\\', '_')\n",
    "\n",
    "        with open(file_path, 'rb') as f:\n",
    "            file_data = f.read()\n",
    "            base64_data = base64.b64encode(file_data).decode('utf-8')\n",
    "        \n",
    "        inputs_data.append({\n",
    "            'name': name,\n",
    "            'data': base64_data\n",
    "        })\n",
    "\n",
    "analysis_poller = await client.content_analyzers.begin_analyze(\n",
    "    analyzer_id=analyzer_id, \n",
    "    inputs=inputs_data, \n",
    "    content_type=\"application/json\")\n",
    "\n",
    " # Wait for analysis completion\n",
    "print(f\"â³ Waiting for document analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(f\"âœ… Document analysis completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result\n",
    "analysis_operation_id = extract_operation_id_from_poller(\n",
    "    analysis_poller, PollerType.ANALYZE_CALL\n",
    ")\n",
    "print(f\"ðŸ“‹ Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "# Get the analysis result using the operation ID\n",
    "print(\n",
    "    f\"ðŸ” Getting analysis result using operation ID '{analysis_operation_id}'...\"\n",
    ")\n",
    "operation_status = await client.content_analyzers.get_result(\n",
    "    operation_id=analysis_operation_id,\n",
    ")\n",
    "\n",
    "print(f\"âœ… Analysis result retrieved successfully!\")\n",
    "print(f\"   Operation ID: {operation_status.id}\")\n",
    "print(f\"   Status: {operation_status.status}\")\n",
    "\n",
    "# The actual analysis result is in operation_status.result\n",
    "operation_result = operation_status.result\n",
    "if operation_result is None:\n",
    "    print(\"âš ï¸  No analysis result available\")\n",
    "\n",
    "print(f\"   Result contains {len(operation_result.contents)} contents\")\n",
    "\n",
    "# Save the analysis result to a file\n",
    "saved_file_path = save_json_to_file(\n",
    "    result=operation_result.as_dict(),\n",
    "    filename_prefix=\"bonus_content_analyzer_get_result\",\n",
    ")\n",
    "print(f\"ðŸ’¾ Analysis result saved to: {saved_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Analyze Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(operation_result[\"contents\"][0].as_dict()[\"fields\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine `LineItemCorroboration` Field in Detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `ReportingOfficer` field is only present in the car accident report, while fields such as `VIN` come exclusively from the repair estimate document. This demonstrates how information is extracted from both documents to generate a single unified result.\n",
    "> \n",
    "> Multiple input documents are combined to produce one consolidated output. This is a single-analysis result, unlike a batch model where N input documents yield N outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = operation_result[\"contents\"][0][\"fields\"][\"LineItemCorroboration\"]\n",
    "print(json.dumps(fields.as_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Within the `LineItemCorroboration` field, each line item from the *repair estimate document* is extracted along with its claim status and evidence. Items not covered by the policy, such as a Starbucks drink and hotel stay, are marked as suspicious. Valid damage repairs supported by the claim documents and permitted under the policy are confirmed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Delete the Analyzer for the Second Sample After Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await client.content_analyzers.delete(analyzer_id_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
