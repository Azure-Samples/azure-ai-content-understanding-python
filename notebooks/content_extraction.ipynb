{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Content from Your File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the Content Understanding API to extract semantic content from multimodal files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "1. Ensure your Azure AI service is configured by following the [configuration steps](../README.md#configure-azure-ai-service-resource).\n",
    "2. Install the required packages to run this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure AI Content Understanding Client\n",
    "\n",
    "> The [AzureContentUnderstandingClient](../python/content_understanding_client.py) is a utility class that provides functions to interact with the Content Understanding API. Prior to the official release of the Content Understanding SDK, it serves as a lightweight SDK.\n",
    ">\n",
    "> Fill in the constants **AZURE_AI_ENDPOINT**, **AZURE_AI_API_VERSION**, and **AZURE_AI_API_KEY** with the details from your Azure AI Service.\n",
    "\n",
    "> ‚ö†Ô∏è Important:\n",
    "You must update the code below to use your preferred Azure authentication method.\n",
    "Look for the `# IMPORTANT` comments in the code and modify those sections accordingly.\n",
    "Skipping this step may cause the sample to not run correctly.\n",
    "\n",
    "> ‚ö†Ô∏è Note: While using a subscription key is supported, it is strongly recommended to use a token provider with Azure Active Directory (AAD) for enhanced security in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.ai.contentunderstanding.aio import ContentUnderstandingClient\n",
    "from azure.ai.contentunderstanding.models import (\n",
    "    AnalyzeResult,\n",
    "    ContentAnalyzer,\n",
    "    ContentAnalyzerConfig,\n",
    "    AnalysisMode,\n",
    "    ProcessingLocation,\n",
    "    AudioVisualContent,\n",
    ")\n",
    "from datetime import datetime\n",
    "from typing import Any\n",
    "import uuid\n",
    "\n",
    "# Add the parent directory to the Python path to import the sample_helper module\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'python'))\n",
    "from extension.sample_helper import (\n",
    "    extract_operation_id_from_poller,\n",
    "    PollerType,\n",
    "    save_json_to_file,\n",
    "    save_keyframe_image_to_file,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "endpoint = os.environ.get(\"AZURE_CONTENT_UNDERSTANDING_ENDPOINT\")\n",
    "# Return AzureKeyCredential if AZURE_CONTENT_UNDERSTANDING_KEY is set, otherwise DefaultAzureCredential\n",
    "key = os.getenv(\"AZURE_CONTENT_UNDERSTANDING_KEY\")\n",
    "credential = AzureKeyCredential(key) if key else DefaultAzureCredential()\n",
    "# Create the ContentUnderstandingClient\n",
    "client = ContentUnderstandingClient(endpoint=endpoint, credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Content\n",
    "\n",
    "The Content Understanding API extracts all textual content from a given document file. In addition to text extraction, it performs a comprehensive layout analysis to identify and categorize tables and figures within the document. The output is presented in a structured markdown format, ensuring clarity and ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_sample_file = '../data/invoice.pdf'\n",
    "analyzer_id = 'prebuilt-documentAnalyzer'\n",
    "\n",
    "with open(analyzer_sample_file, \"rb\") as f:\n",
    "    pdf_bytes = f.read()\n",
    "\n",
    "print(f\"üîç Analyzing {analyzer_sample_file} with prebuilt-documentAnalyzer...\")\n",
    "poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=analyzer_id,\n",
    "    input=pdf_bytes,\n",
    "    content_type=\"application/pdf\"\n",
    ")\n",
    "result: AnalyzeResult = await poller.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The markdown output contains detailed layout information, which is especially useful for Retrieval-Augmented Generation (RAG) scenarios. You can paste the markdown into a viewer such as Visual Studio Code to preview the layout structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìÑ Markdown Content:\")\n",
    "print(\"=\" * 50)\n",
    "content = result.contents[0]\n",
    "print(content.markdown)\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can access layout information including `words` and `lines` within the `pages` node, paragraph details under `paragraphs`, and tables listed in the `tables` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(result.as_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Content\n",
    "The API provides detailed analysis of spoken language, enabling developers to build applications such as voice recognition, customer service analytics, and conversational AI. The output structure facilitates extraction and analysis of different conversation components for further processing or insights.\n",
    "\n",
    "Key features include:\n",
    "1. **Speaker Identification:** Each phrase is linked to a specific speaker (e.g., \"Speaker 2\"), enabling clear differentiation in multi-participant conversations.\n",
    "2. **Timing Information:** Each transcription includes precise timing data.\n",
    "    - startTimeMs: The time (in milliseconds) when the phrase begins.\n",
    "    - endTimeMs: The time (in milliseconds) when the phrase ends.\n",
    "    This information is crucial for applications like video subtitles and audio-text synchronization.\n",
    "3. **Text Content:** The actual spoken text, such as \"Thank you for calling Woodgrove Travel,\" representing the main transcription.\n",
    "4. **Confidence Score:** Each phrase has a confidence score (e.g., 0.933) indicating transcription reliability.\n",
    "5. **Word-Level Breakdown:** Detailed timing for each word supports advanced speech analysis and improvements in speech recognition.\n",
    "6. **Locale Specification:** The locale (e.g., \"en-US\") informs the transcription process of regional dialects and pronunciation nuances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_id = f\"audio-sample-{datetime.now().strftime('%Y%m%d')}-{datetime.now().strftime('%H%M%S')}-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Create a marketing video analyzer using object model\n",
    "print(f\"üîß Creating marketing video analyzer '{analyzer_id}'...\")\n",
    "\n",
    "audio_analyzer = ContentAnalyzer(\n",
    "    base_analyzer_id=\"prebuilt-audioAnalyzer\",\n",
    "    config=ContentAnalyzerConfig(return_details=True),\n",
    "    description=\"Marketing audio analyzer for result file demo\",\n",
    "    mode=AnalysisMode.STANDARD,\n",
    "    processing_location=ProcessingLocation.GLOBAL,\n",
    "    tags={\"demo_type\": \"audio_analysis\"},\n",
    ")\n",
    "\n",
    " # Start the analyzer creation operation\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=analyzer_id,\n",
    "    resource=audio_analyzer,\n",
    ")\n",
    "\n",
    "# Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"üìã Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"‚è≥ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"‚úÖ Analyzer '{analyzer_id}' created successfully!\")\n",
    "\n",
    "# Analyze audio file with the created analyzer\n",
    "audio_file_path = \"../data/audio.wav\"\n",
    "print(f\"üîç Analyzing audio file from path: {audio_file_path} with analyzer '{analyzer_id}'...\")\n",
    "\n",
    "with open(audio_file_path, \"rb\") as f:\n",
    "    audio_data = f.read()\n",
    "\n",
    "# Begin audio analysis operation\n",
    "print(f\"üé¨ Starting audio analysis with analyzer '{analyzer_id}'...\")\n",
    "analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=analyzer_id,\n",
    "    input=audio_data,\n",
    "    content_type=\"application/octet-stream\",\n",
    ")\n",
    "\n",
    " # Wait for analysis completion\n",
    "print(f\"‚è≥ Waiting for audio analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(f\"‚úÖ Audio analysis completed successfully!\")\n",
    "print(f\"üìä Analysis Results: {json.dumps(analysis_result.as_dict(), indent=2)}\")\n",
    "\n",
    "# Clean up the created analyzer (demo cleanup)\n",
    "print(f\"üóëÔ∏è  Deleting analyzer '{analyzer_id}' (demo cleanup)...\")\n",
    "await client.content_analyzers.delete(analyzer_id=analyzer_id)\n",
    "print(f\"‚úÖ Analyzer '{analyzer_id}' deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Content\n",
    "The video output provides detailed metadata about audiovisual content, specifically video shots. Key features include:\n",
    "\n",
    "1. **Shot Information:** Each shot has a start and end time with a unique identifier. For example, 'Shot 0:0.0 to 0:2.800' includes a transcript and key frames.\n",
    "2. **Transcript:** Audio transcripts formatted in WEBVTT facilitate synchronization with video playback. It captures spoken content and specifies the timing of the dialogue.\n",
    "3. **Key Frames:** A collection of key frames (images) represent important moments in the video, allowing visualization of specific timestamps.\n",
    "4. **Description:** Each shot includes a descriptive summary, providing context about the visuals presented. This helps in understanding the scene or subject matter without watching the video.\n",
    "5. **Audio Visual Metadata:** Information such as video dimensions (width, height), type (audiovisual), and key frame timestamps.\n",
    "6. **Transcript Phrases:** Specific dialog phrases with timing and speaker attribution enhance usability for applications like closed captioning and search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_id = f\"video-sample-{datetime.now().strftime('%Y%m%d')}-{datetime.now().strftime('%H%M%S')}-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "video_analyzer = ContentAnalyzer(\n",
    "    base_analyzer_id='prebuilt-videoAnalyzer', \n",
    "    config=ContentAnalyzerConfig(return_details=True), \n",
    "    description=\"Marketing video analyzer for result file demo\", \n",
    "    mode=AnalysisMode.STANDARD,\n",
    "    processing_location=ProcessingLocation.GLOBAL,\n",
    "    tags={\"demo_type\": \"video_analysis\"}\n",
    ")\n",
    "\n",
    "# Start the analyzer creation operation\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=analyzer_id,\n",
    "    resource=video_analyzer,\n",
    ")\n",
    "\n",
    " # Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"üìã Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"‚è≥ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"‚úÖ Analyzer '{analyzer_id}' created successfully!\")\n",
    "\n",
    "# Use the FlightSimulator.mp4 video file from remote location\n",
    "video_file_path = \"../data/FlightSimulator.mp4\"\n",
    "print(f\"üìπ Using video file from URL: {video_file_path}\")\n",
    "\n",
    "with open(video_file_path, \"rb\") as f:\n",
    "    video_data = f.read()\n",
    "\n",
    "# Begin video analysis operation\n",
    "print(f\"üé¨ Starting video analysis with analyzer '{analyzer_id}'...\")\n",
    "analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=analyzer_id,\n",
    "    input=video_data,\n",
    "    content_type=\"application/octet-stream\"\n",
    ")\n",
    "\n",
    "# Wait for analysis completion\n",
    "print(f\"‚è≥ Waiting for video analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(json.dumps(analysis_result.as_dict(), indent=2))\n",
    "print(f\"‚úÖ Video analysis completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result_file\n",
    "analysis_operation_id = extract_operation_id_from_poller(\n",
    "    analysis_poller, PollerType.ANALYZE_CALL\n",
    ")\n",
    "print(f\"üìã Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "# Get the result to see what files are available\n",
    "print(f\"üîç Getting analysis result to find available files...\")\n",
    "operation_status = await client.content_analyzers.get_result(\n",
    "    operation_id=analysis_operation_id,\n",
    ")\n",
    "\n",
    "# The actual analysis result is in operation_status.result\n",
    "operation_result: Any = operation_status.result\n",
    "if operation_result is None:\n",
    "    print(\"‚ö†Ô∏è  No analysis result available\")\n",
    "else:\n",
    "    print(f\"‚úÖ Analysis result contains {len(operation_result.contents)} contents\")\n",
    "\n",
    "# Look for keyframe times in the analysis result\n",
    "keyframe_times_ms: list[int] = []\n",
    "for content in operation_result.contents:\n",
    "    if isinstance(content, AudioVisualContent):\n",
    "        video_content: AudioVisualContent = content\n",
    "        print(f\"KeyFrameTimesMs: {video_content.key_frame_times_ms}\")\n",
    "        print(video_content)\n",
    "        keyframe_times_ms.extend(video_content.key_frame_times_ms or [])\n",
    "        print(f\"üìπ Found {len(keyframe_times_ms)} keyframes in video content\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Content is not an AudioVisualContent: {content}\")\n",
    "\n",
    "if not keyframe_times_ms:\n",
    "    print(\"‚ö†Ô∏è  No keyframe times found in the analysis result\")\n",
    "else:\n",
    "    print(f\"üñºÔ∏è  Found {len(keyframe_times_ms)} keyframe times in milliseconds\")\n",
    "\n",
    "# Build keyframe filenames using the time values\n",
    "keyframe_files = [f\"keyFrame.{time_ms}\" for time_ms in keyframe_times_ms]\n",
    "\n",
    "# Download and save a few keyframe images as examples (first, middle, last)\n",
    "if len(keyframe_files) >= 3:\n",
    "    frames_to_download = {\n",
    "        keyframe_files[0],\n",
    "        keyframe_files[-1],\n",
    "        keyframe_files[len(keyframe_files) // 2],\n",
    "    }\n",
    "else:\n",
    "    frames_to_download = set(keyframe_files)\n",
    "\n",
    "files_to_download = list(frames_to_download)\n",
    "print(\n",
    "    f\"üì• Downloading {len(files_to_download)} keyframe images as examples: {files_to_download}\"\n",
    ")\n",
    "\n",
    "for keyframe_id in files_to_download:\n",
    "    print(f\"üì• Getting result file: {keyframe_id}\")\n",
    "\n",
    "    # Get the result file (keyframe image)\n",
    "    response: Any = await client.content_analyzers.get_result_file(\n",
    "        operation_id=analysis_operation_id,\n",
    "        path=keyframe_id,\n",
    "    )\n",
    "\n",
    "    # Handle the response which may be bytes or an async iterator of bytes\n",
    "    if isinstance(response, (bytes, bytearray)):\n",
    "        image_content = bytes(response)\n",
    "    else:\n",
    "        chunks: list[bytes] = []\n",
    "        async for chunk in response:\n",
    "            chunks.append(chunk)\n",
    "        image_content = b\"\".join(chunks)\n",
    "\n",
    "    print(\n",
    "        f\"‚úÖ Retrieved image file for {keyframe_id} ({len(image_content)} bytes)\"\n",
    "    )\n",
    "\n",
    "    # Save the image file\n",
    "    saved_file_path = save_keyframe_image_to_file(\n",
    "        image_content=image_content,\n",
    "        keyframe_id=keyframe_id,\n",
    "        test_name=\"content_analyzers_get_result_file\",\n",
    "        test_py_file_dir=os.getcwd(),\n",
    "        identifier=analyzer_id,\n",
    "    )\n",
    "    print(f\"üíæ Keyframe image saved to: {saved_file_path}\")\n",
    "\n",
    "# Clean up the created analyzer (demo cleanup)\n",
    "print(f\"üóëÔ∏è  Deleting analyzer '{analyzer_id}' (demo cleanup)...\")\n",
    "await client.content_analyzers.delete(analyzer_id=analyzer_id)\n",
    "print(f\"‚úÖ Analyzer '{analyzer_id}' deleted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Content with Face Recognition\n",
    "This is a gated feature. To enable it, please follow the registration process outlined in [Azure AI Resource Face Gating](https://learn.microsoft.com/en-us/legal/cognitive-services/computer-vision/limited-access-identity?context=%2Fazure%2Fai-services%2Fcomputer-vision%2Fcontext%2Fcontext#registration-process).\n",
    "In the registration form, select:\n",
    "`[Video Indexer] Facial Identification (1:N or 1:1 matching)` to search for faces within media or entertainment video archives and generate metadata for these use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_id = f\"video-sample-{datetime.now().strftime('%Y%m%d')}-{datetime.now().strftime('%H%M%S')}-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Create a marketing video analyzer using object model\n",
    "print(f\"üîß Creating marketing video analyzer '{analyzer_id}'...\")\n",
    "\n",
    "video_analyzer = ContentAnalyzer(\n",
    "    base_analyzer_id='prebuilt-videoAnalyzer',\n",
    "    config=ContentAnalyzerConfig(\n",
    "        return_details=True,\n",
    "    ),\n",
    "    description=\"Marketing video analyzer for result file demo\",\n",
    "    mode=AnalysisMode.STANDARD,\n",
    "    processing_location=ProcessingLocation.GLOBAL,\n",
    "    tags={\"demo_type\": \"video_analysis\"},\n",
    ")\n",
    "\n",
    "# Start the analyzer creation operation\n",
    "poller = await client.content_analyzers.begin_create_or_replace(\n",
    "    analyzer_id=analyzer_id,\n",
    "    resource=video_analyzer,\n",
    ")\n",
    "\n",
    "# Extract operation ID from the poller\n",
    "operation_id = extract_operation_id_from_poller(\n",
    "    poller, PollerType.ANALYZER_CREATION\n",
    ")\n",
    "print(f\"üìã Extracted creation operation ID: {operation_id}\")\n",
    "\n",
    "# Wait for the analyzer to be created\n",
    "print(f\"‚è≥ Waiting for analyzer creation to complete...\")\n",
    "await poller.result()\n",
    "print(f\"‚úÖ Analyzer '{analyzer_id}' created successfully!\")\n",
    "\n",
    "# Use the FlightSimulator.mp4 video file from remote location\n",
    "video_file_path = \"../data/FlightSimulator.mp4\"\n",
    "print(f\"üìπ Using video file from URL: {video_file_path}\")\n",
    "\n",
    "with open(video_file_path, \"rb\") as f:\n",
    "    video_data = f.read()\n",
    "\n",
    "# Begin video analysis operation\n",
    "print(f\"üé¨ Starting video analysis with analyzer '{analyzer_id}'...\")\n",
    "analysis_poller = await client.content_analyzers.begin_analyze_binary(\n",
    "    analyzer_id=analyzer_id,\n",
    "    input=video_data,\n",
    "    content_type=\"application/octet-stream\"\n",
    ")\n",
    "\n",
    "# Wait for analysis completion\n",
    "print(f\"‚è≥ Waiting for video analysis to complete...\")\n",
    "analysis_result = await analysis_poller.result()\n",
    "print(\"result: \", json.dumps(analysis_result.as_dict(), indent=2))\n",
    "print(f\"‚úÖ Video analysis completed successfully!\")\n",
    "\n",
    "# Extract operation ID for get_result_file\n",
    "analysis_operation_id = extract_operation_id_from_poller(\n",
    "    analysis_poller, PollerType.ANALYZE_CALL\n",
    ")\n",
    "print(f\"üìã Extracted analysis operation ID: {analysis_operation_id}\")\n",
    "\n",
    "# Get the result to see what files are available\n",
    "print(f\"üîç Getting analysis result to find available files...\")\n",
    "operation_status = await client.content_analyzers.get_result(\n",
    "    operation_id=analysis_operation_id,\n",
    ")\n",
    "\n",
    "# The actual analysis result is in operation_status.result\n",
    "operation_result: Any = operation_status.result\n",
    "if operation_result is None:\n",
    "    print(\"‚ö†Ô∏è  No analysis result available\")\n",
    "else:\n",
    "    print(f\"‚úÖ Analysis result contains {len(operation_result.contents)} contents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and Save Key Frames and Face Thumbnails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sets to store unique face IDs\n",
    "face_ids = set()\n",
    "\n",
    "# Look for keyframe times in the analysis result\n",
    "keyframe_times_ms: list[int] = []\n",
    "for content in operation_result.contents:\n",
    "    if isinstance(content, AudioVisualContent):\n",
    "        video_content: AudioVisualContent = content\n",
    "        print(f\"KeyFrameTimesMs: {video_content.key_frame_times_ms}\")\n",
    "        print(video_content)\n",
    "        keyframe_times_ms.extend(video_content.key_frame_times_ms or [])\n",
    "        print(f\"üìπ Found {len(keyframe_times_ms)} keyframes in video content\")\n",
    "        faces = content.get(\"faces\", [])\n",
    "        if isinstance(faces, list):\n",
    "            for face in faces:\n",
    "                face_id = face.get(\"faceId\")\n",
    "                if face_id:\n",
    "                    face_ids.add(f\"face.{face_id}\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Content is not an AudioVisualContent: {content}\")\n",
    "\n",
    "if not keyframe_times_ms:\n",
    "    print(\"‚ö†Ô∏è  No keyframe times found in the analysis result\")\n",
    "else:\n",
    "    print(f\"üñºÔ∏è  Found {len(keyframe_times_ms)} keyframe times in milliseconds\")\n",
    "\n",
    "# Build keyframe filenames using the time values\n",
    "keyframe_files = [f\"keyFrame.{time_ms}\" for time_ms in keyframe_times_ms]\n",
    "\n",
    "# Download and save a few keyframe images as examples (first, middle, last)\n",
    "if len(keyframe_files) >= 3:\n",
    "    frames_to_download = {\n",
    "        keyframe_files[0],\n",
    "        keyframe_files[-1],\n",
    "        keyframe_files[len(keyframe_files) // 2],\n",
    "    }\n",
    "else:\n",
    "    frames_to_download = set(keyframe_files)\n",
    "\n",
    "files_to_download = list(frames_to_download)\n",
    "print(\n",
    "    f\"üì• Downloading {len(files_to_download)} keyframe images as examples: {files_to_download}\"\n",
    ")\n",
    "\n",
    "for keyframe_id in files_to_download:\n",
    "    print(f\"üì• Getting result file: {keyframe_id}\")\n",
    "\n",
    "    # Get the result file (keyframe image)\n",
    "    response: Any = await client.content_analyzers.get_result_file(\n",
    "        operation_id=analysis_operation_id,\n",
    "        path=keyframe_id,\n",
    "    )\n",
    "\n",
    "    # Handle the response which may be bytes or an async iterator of bytes\n",
    "    if isinstance(response, (bytes, bytearray)):\n",
    "        image_content = bytes(response)\n",
    "    else:\n",
    "        chunks: list[bytes] = []\n",
    "        async for chunk in response:\n",
    "            chunks.append(chunk)\n",
    "        image_content = b\"\".join(chunks)\n",
    "\n",
    "    print(\n",
    "        f\"‚úÖ Retrieved image file for {keyframe_id} ({len(image_content)} bytes)\"\n",
    "    )\n",
    "\n",
    "    # Save the image file\n",
    "    saved_file_path = save_keyframe_image_to_file(\n",
    "        image_content=image_content,\n",
    "        keyframe_id=keyframe_id,\n",
    "        test_name=\"content_analyzers_get_result_file\",\n",
    "        test_py_file_dir=os.getcwd(),\n",
    "        identifier=analyzer_id,\n",
    "    )\n",
    "    print(f\"üíæ Keyframe image saved to: {saved_file_path}\")\n",
    "\n",
    "# Clean up the created analyzer (demo cleanup)\n",
    "print(f\"üóëÔ∏è  Deleting analyzer '{analyzer_id}' (demo cleanup)...\")\n",
    "await client.content_analyzers.delete(analyzer_id=analyzer_id)\n",
    "print(f\"‚úÖ Analyzer '{analyzer_id}' deleted successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
